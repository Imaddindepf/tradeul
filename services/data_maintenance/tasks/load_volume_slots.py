"""
Load Volume Slots Task
Carga volume slots de 5 minutos para cÃ¡lculo de RVOL
"""

import asyncio
import sys
sys.path.append('/app')

from datetime import date, datetime, timedelta
from typing import Dict, List
import httpx

from shared.utils.redis_client import RedisClient
from shared.utils.timescale_client import TimescaleClient
from shared.utils.logger import get_logger

# Importar desde shared/utils
from shared.utils.trading_days import get_trading_days
from shared.config.settings import settings

logger = get_logger(__name__)


class LoadVolumeSlotsTask:
    """
    Tarea: Cargar volume slots de 5 minutos
    
    - Carga Ãºltimos 10 dÃ­as de agregados de 1 minuto
    - Convierte a slots de 5 minutos
    - Actualiza volume_slots en TimescaleDB para RVOL
    """
    
    name = "volume_slots"
    
    def __init__(self, redis_client: RedisClient, timescale_client: TimescaleClient):
        self.redis = redis_client
        self.db = timescale_client
    
    async def execute(self, target_date: date) -> Dict:
        """
        Ejecutar carga de volume slots
        
        Args:
            target_date: Fecha objetivo
        
        Returns:
            Dict con resultado
        """
        logger.info(
            "volume_slots_task_starting",
            target_date=target_date.isoformat()
        )
        
        try:
            # Obtener Ãºltimos 10 dÃ­as de trading potenciales
            all_trading_days = get_trading_days(10)
            
            # ðŸ” DETECTAR QUÃ‰ DÃAS YA EXISTEN EN LA BD
            logger.info("detecting_existing_days_in_db")
            existing_dates_query = """
                SELECT DISTINCT date 
                FROM volume_slots 
                WHERE date >= $1 
                ORDER BY date DESC
            """
            oldest_date = min(all_trading_days)
            existing_rows = await self.db.fetch(existing_dates_query, oldest_date)
            existing_dates = {row['date'] for row in existing_rows}
            
            # Filtrar solo los dÃ­as FALTANTES
            trading_days = [d for d in all_trading_days if d not in existing_dates]
            
            if existing_dates:
                logger.info(
                    "existing_days_found",
                    existing_count=len(existing_dates),
                    last_3_dates=sorted([d.isoformat() for d in existing_dates], reverse=True)[:3]
                )
            
            if not trading_days:
                logger.info("all_days_already_loaded", message="No hay dÃ­as faltantes")
                return {
                    "success": True,
                    "message": "All days already loaded",
                    "symbols_processed": 0,
                    "records_inserted": 0,
                    "days_skipped": len(existing_dates)
                }
            
            logger.info(
                "missing_days_detected",
                missing_count=len(trading_days),
                missing_dates=[d.isoformat() for d in sorted(trading_days, reverse=True)]
            )
            
            # Obtener sÃ­mbolos activos
            symbols = await self._get_active_symbols()
            
            if not symbols:
                logger.warning("no_symbols_found")
                return {
                    "success": False,
                    "error": "No symbols found"
                }
            
            logger.info(
                "volume_slots_symbols_loaded",
                count=len(symbols),
                days_to_load=len(trading_days)
            )
            
            # Procesar en paralelo
            async with httpx.AsyncClient() as client:
                records_inserted = 0
                semaphore = asyncio.Semaphore(200)  # Max 200 concurrent (servicio sin rate limits)
                
                async def load_with_semaphore(symbol: str):
                    async with semaphore:
                        return await self._load_symbol_slots(client, symbol, trading_days)
                
                tasks = [load_with_semaphore(sym) for sym in symbols]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, int):
                        records_inserted += result
            
            logger.info(
                "volume_slots_task_completed",
                symbols_processed=len(symbols),
                records_inserted=records_inserted,
                days_loaded=len(trading_days),
                days_skipped=len(existing_dates)
            )
            
            # ðŸ”¥ VALIDACIÃ“N: Verificar datos
            # Si ya tenemos suficientes dÃ­as completos, consideramos Ã©xito
            MIN_COMPLETE_DAYS = 5  # Necesitamos al menos 5 dÃ­as para RVOL
            
            if len(existing_dates) >= MIN_COMPLETE_DAYS:
                logger.info(
                    "volume_slots_validation_passed",
                    complete_days=len(existing_dates),
                    new_records=records_inserted,
                    message="Sufficient historical data available"
                )
            elif records_inserted == 0 and len(trading_days) > 0:
                logger.warning(
                    "volume_slots_no_new_data",
                    days_attempted=len(trading_days),
                    days_complete=len(existing_dates),
                    message="No new data, may be normal for current day"
                )
            
            # Solo falla si no tenemos suficientes dÃ­as histÃ³ricos
            if len(existing_dates) < MIN_COMPLETE_DAYS and records_inserted == 0:
                logger.error(
                    "insufficient_volume_slots_history",
                    expected_min_days=MIN_COMPLETE_DAYS,
                    actual_days=len(existing_dates)
                )
                return {
                    "success": False,
                    "error": f"Insufficient history: {len(existing_dates)} days, need >= {MIN_COMPLETE_DAYS}",
                    "symbols_processed": len(symbols),
                    "records_inserted": records_inserted,
                    "days_loaded": len(trading_days),
                    "days_skipped": len(existing_dates)
                }
            
            return {
                "success": True,
                "symbols_processed": len(symbols),
                "records_inserted": records_inserted,
                "days_loaded": len(trading_days),
                "days_skipped": len(existing_dates)
            }
        
        except Exception as e:
            logger.error(
                "volume_slots_task_failed",
                error=str(e),
                error_type=type(e).__name__
            )
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _get_active_symbols(self) -> List[str]:
        """Obtener sÃ­mbolos activos"""
        try:
            query = """
                SELECT DISTINCT symbol 
                FROM tickers_unified 
                WHERE is_actively_trading = true
                ORDER BY symbol
            """
            rows = await self.db.fetch(query)
            return [row['symbol'] for row in rows]
        except Exception as e:
            logger.error("failed_to_get_symbols", error=str(e))
            return []
    
    async def _load_symbol_slots(
        self,
        client: httpx.AsyncClient,
        symbol: str,
        trading_days: List[date]
    ) -> int:
        """Cargar volume slots para un sÃ­mbolo"""
        total_inserted = 0
        
        for day in trading_days:
            try:
                # Fetch 1-minute aggregates
                aggs = await self._fetch_minute_aggs(client, symbol, day)
                if not aggs:
                    continue
                
                # Convert to 5-minute slots
                slots = self._convert_to_5min_slots(aggs, day)
                if not slots:
                    continue
                
                # Insert into database
                inserted = await self._insert_slots(symbol, day, slots)
                total_inserted += inserted
            
            except Exception as e:
                logger.debug(f"Error loading {symbol} {day}: {e}")
                continue
        
        return total_inserted
    
    async def _fetch_minute_aggs(
        self,
        client: httpx.AsyncClient,
        symbol: str,
        day: date
    ) -> List[Dict]:
        """Obtener agregados de 1 minuto de Polygon"""
        url = f"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/minute/{day}/{day}"
        
        try:
            resp = await client.get(
                url,
                params={
                    "adjusted": "true",
                    "sort": "asc",
                    "limit": 50000,
                    "apiKey": settings.POLYGON_API_KEY
                },
                timeout=15.0
            )
            
            if resp.status_code == 200:
                data = resp.json()
                return data.get('results', [])
        
        except Exception as e:
            logger.debug(f"Error fetching {symbol} {day}: {e}")
        
        return []
    
    def _convert_to_5min_slots(self, aggs: List[Dict], day: date) -> List[Dict]:
        """
        Convertir agregados de 1 min a slots de 5 min con VOLUMEN ACUMULADO
        
        MÃ‰TODO PINESCRIPT (igual que load_massive_parallel.py):
        - Acumula BARRA POR BARRA (minuto a minuto)
        - Mantiene el Ãºltimo valor acumulado de cada slot
        - Extended hours: 4:00-20:00 ET (192 slots)
        """
        from zoneinfo import ZoneInfo
        from datetime import time
        
        if not aggs:
            return []
        
        TIMEZONE = ZoneInfo("America/New_York")
        accumulated = 0
        slots_dict = {}
        
        # ðŸ”¥ ACUMULACIÃ“N PINESCRIPT: barra por barra
        for bar in sorted(aggs, key=lambda x: x['t']):
            dt = datetime.fromtimestamp(bar['t'] / 1000, tz=TIMEZONE)
            accumulated += bar.get('v', 0)  # ACUMULAR como PineScript
            
            # Extended hours: 4:00-20:00 ET
            if dt.hour < 4 or dt.hour >= 20:
                continue
            
            # Calcular slot (0-191): desde 4:00 AM
            slot_num = ((dt.hour - 4) * 60 + dt.minute) // 5
            slot_h = 4 + (slot_num * 5) // 60
            slot_m = (slot_num * 5) % 60
            
            # Guardar el ÃšLTIMO valor acumulado de cada slot
            # (sobreescribe si hay mÃºltiples barras en el mismo slot)
            slots_dict[slot_num] = {
                "slot_index": slot_num,
                "slot_time": time(slot_h, slot_m, 0),  # â† OBJETO time, no string
                "volume_accumulated": accumulated,  # â† VOLUMEN ACUMULADO total
                "trades_count": bar.get('n', 0),
                "avg_price": bar.get('c', 0.0)
            }
        
        return list(slots_dict.values())
    
    async def _insert_slots(self, symbol: str, day: date, slots: List[Dict]) -> int:
        """
        Insertar slots en la base de datos con volumen ACUMULADO
        
        IMPORTANTE: volume_accumulated es el volumen total desde inicio del dÃ­a
        hasta ese slot, NO solo el volumen de ese slot de 5 minutos.
        """
        if not slots:
            return 0
        
        query = """
            INSERT INTO volume_slots (date, symbol, slot_number, slot_time, volume_accumulated, trades_count, avg_price)
            VALUES ($1, $2, $3, $4, $5, $6, $7)
            ON CONFLICT (date, symbol, slot_number)
            DO UPDATE SET 
                volume_accumulated = EXCLUDED.volume_accumulated,
                trades_count = EXCLUDED.trades_count,
                avg_price = EXCLUDED.avg_price
        """
        
        records = [
            (
                day,
                symbol,
                slot["slot_index"],
                slot["slot_time"],
                slot["volume_accumulated"],
                slot.get("trades_count", 0),
                slot.get("avg_price", 0.0)
            )
            for slot in slots
        ]
        
        try:
            await self.db.executemany(query, records)
            return len(records)
        except Exception as e:
            logger.error(
                "failed_to_insert_slots",
                symbol=symbol,
                date=day.isoformat(),
                error=str(e)
            )
            return 0

