"""
Redis Health Checker & Auto-Recovery
Detecta autom√°ticamente si Redis est√° vac√≠o o tiene datos faltantes
y ejecuta una recuperaci√≥n completa de todos los datos cr√≠ticos
"""

import asyncio
from datetime import date, timedelta
from typing import Dict, List, Tuple
import sys
sys.path.append('/app')

from shared.utils.redis_client import RedisClient
from shared.utils.timescale_client import TimescaleClient
from shared.utils.logger import get_logger

logger = get_logger(__name__)


class RedisHealthChecker:
    """
    Verificador de salud de Redis con auto-recuperaci√≥n
    
    Detecta:
    - Redis completamente vac√≠o (post-FLUSHDB)
    - Datos cr√≠ticos faltantes (universe, metadata, RVOL, ATR)
    - Datos desactualizados (>24 horas)
    
    Recupera:
    - ticker:universe (SET de s√≠mbolos activos)
    - metadata:ticker:{symbol} (metadata individual por ticker)
    - rvol:hist:avg:{symbol}:5 (promedios hist√≥ricos RVOL)
    - atr:daily (hash de ATR por ticker)
    """
    
    def __init__(self, redis_client: RedisClient, timescale_client: TimescaleClient):
        self.redis = redis_client
        self.db = timescale_client
        
        # Umbrales para considerar datos "cr√≠ticos"
        self.min_universe_size = 10000  # M√≠nimo de tickers esperados
        self.min_metadata_keys = 10000  # M√≠nimo de metadatos esperados
        self.min_rvol_keys = 10000     # M√≠nimo de hashes RVOL esperados
        self.min_atr_keys = 1          # M√≠nimo de claves ATR (hash √∫nico)
    
    async def check_and_recover(self) -> Dict:
        """
        Verificar salud de Redis y recuperar si es necesario
        
        Returns:
            Dict con:
            - needs_recovery: bool
            - issues_found: List[str]
            - recovery_executed: bool
            - recovery_results: Dict (si se ejecut√≥ recovery)
        """
        logger.info("üîç Checking Redis health...")
        
        # 1. Verificar qu√© datos cr√≠ticos faltan
        issues = await self._diagnose_redis()
        
        if not issues:
            logger.info("‚úÖ Redis is healthy - all critical data present")
            return {
                "needs_recovery": False,
                "issues_found": [],
                "recovery_executed": False
            }
        
        logger.warning(
            "‚ö†Ô∏è Redis health issues detected",
            issues=issues,
            count=len(issues)
        )
        
        # 2. Ejecutar recuperaci√≥n autom√°tica
        logger.info("üöÄ Initiating automatic Redis recovery...")
        recovery_results = await self._execute_recovery(issues)
        
        return {
            "needs_recovery": True,
            "issues_found": issues,
            "recovery_executed": True,
            "recovery_results": recovery_results
        }
    
    async def _diagnose_redis(self) -> List[str]:
        """
        Diagnosticar qu√© datos faltan en Redis
        
        Returns:
            Lista de issues encontrados (vac√≠a si todo est√° bien)
        """
        issues = []
        
        try:
            # 1. Verificar DBSIZE total
            dbsize = await self.redis.dbsize()
            
            if dbsize == 0:
                issues.append("redis_completely_empty")
                logger.warning("üö® Redis is COMPLETELY EMPTY (DBSIZE=0)")
                # Si est√° completamente vac√≠o, no necesitamos verificar m√°s
                return issues
            
            logger.info(f"Redis DBSIZE: {dbsize}")
            
            # 2. Verificar ticker:universe
            universe_size = await self.redis.scard("ticker:universe")
            
            if universe_size == 0:
                issues.append("missing_ticker_universe")
                logger.warning("‚ùå ticker:universe is missing or empty")
            elif universe_size < self.min_universe_size:
                issues.append("incomplete_ticker_universe")
                logger.warning(
                    f"‚ö†Ô∏è ticker:universe is incomplete ({universe_size} < {self.min_universe_size})"
                )
            else:
                logger.info(f"‚úÖ ticker:universe: {universe_size} symbols")
            
            # 3. Verificar metadata:ticker:*
            metadata_pattern = "metadata:ticker:*"
            metadata_keys = await self.redis.scan_keys(metadata_pattern)
            metadata_count = len(metadata_keys)
            
            if metadata_count == 0:
                issues.append("missing_ticker_metadata")
                logger.warning("‚ùå No ticker metadata found")
            elif metadata_count < self.min_metadata_keys:
                issues.append("incomplete_ticker_metadata")
                logger.warning(
                    f"‚ö†Ô∏è Ticker metadata is incomplete ({metadata_count} < {self.min_metadata_keys})"
                )
            else:
                logger.info(f"‚úÖ Ticker metadata: {metadata_count} keys")
            
            # 4. Verificar rvol:hist:avg:*
            rvol_pattern = "rvol:hist:avg:*"
            rvol_keys = await self.redis.scan_keys(rvol_pattern)
            rvol_count = len(rvol_keys)
            
            if rvol_count == 0:
                issues.append("missing_rvol_averages")
                logger.warning("‚ùå No RVOL historical averages found")
            elif rvol_count < self.min_rvol_keys:
                issues.append("incomplete_rvol_averages")
                logger.warning(
                    f"‚ö†Ô∏è RVOL averages are incomplete ({rvol_count} < {self.min_rvol_keys})"
                )
            else:
                logger.info(f"‚úÖ RVOL historical averages: {rvol_count} hashes")
            
            # 5. Verificar atr:daily
            atr_exists = await self.redis.exists("atr:daily")
            
            if not atr_exists:
                issues.append("missing_atr_data")
                logger.warning("‚ùå ATR data (atr:daily) is missing")
            else:
                # Verificar cu√°ntos tickers tienen ATR
                atr_count = await self.redis.hlen("atr:daily")
                if atr_count < self.min_atr_keys:
                    issues.append("incomplete_atr_data")
                    logger.warning(f"‚ö†Ô∏è ATR data is incomplete ({atr_count} entries)")
                else:
                    logger.info(f"‚úÖ ATR data: {atr_count} tickers")
            
            return issues
        
        except Exception as e:
            logger.error("diagnosis_failed", error=str(e))
            # Si la diagnosis falla, asumir que hay problemas
            return ["diagnosis_failed"]
    
    async def _execute_recovery(self, issues: List[str]) -> Dict:
        """
        Ejecutar recuperaci√≥n completa de Redis
        
        Args:
            issues: Lista de problemas detectados
        
        Returns:
            Dict con resultados de cada tarea ejecutada
        """
        results = {}
        
        try:
            # Si Redis est√° completamente vac√≠o o faltan datos cr√≠ticos,
            # ejecutar TODAS las tareas en orden
            
            # 1. Sincronizar universe y metadata (m√°s r√°pido, sin deps)
            if any(issue in issues for issue in [
                "redis_completely_empty",
                "missing_ticker_universe",
                "incomplete_ticker_universe",
                "missing_ticker_metadata",
                "incomplete_ticker_metadata"
            ]):
                logger.info("üì• Step 1/3: Syncing universe & metadata from TimescaleDB...")
                from tasks.sync_redis import SyncRedisTask
                
                sync_task = SyncRedisTask(self.redis, self.db)
                sync_result = await sync_task.execute(date.today())
                results["sync_redis"] = sync_result
                
                logger.info(
                    "‚úÖ Universe & metadata synced",
                    universe=sync_result.get("universe_synced", 0),
                    metadata=sync_result.get("metadata_synced", 0)
                )
            
            # 2. Calcular RVOL historical averages (requiere volume_slots en DB)
            if any(issue in issues for issue in [
                "redis_completely_empty",
                "missing_rvol_averages",
                "incomplete_rvol_averages"
            ]):
                logger.info("üìä Step 2/3: Calculating RVOL historical averages...")
                from tasks.calculate_rvol_averages import CalculateRVOLHistoricalAveragesTask
                
                rvol_task = CalculateRVOLHistoricalAveragesTask(self.redis, self.db)
                target_date = date.today() - timedelta(days=1)
                rvol_result = await rvol_task.execute(target_date)
                results["calculate_rvol"] = rvol_result
                
                logger.info(
                    "‚úÖ RVOL averages calculated",
                    symbols_processed=rvol_result.get("symbols_processed", 0),
                    redis_inserted=rvol_result.get("redis_inserted", 0)
                )
            
            # 3. Calcular ATR (requiere OHLC en DB)
            if any(issue in issues for issue in [
                "redis_completely_empty",
                "missing_atr_data",
                "incomplete_atr_data"
            ]):
                logger.info("üìà Step 3/3: Calculating ATR for all tickers...")
                from tasks.calculate_atr import CalculateATRTask
                
                atr_task = CalculateATRTask(self.redis, self.db)
                target_date = date.today() - timedelta(days=1)
                atr_result = await atr_task.execute(target_date)
                results["calculate_atr"] = atr_result
                
                logger.info(
                    "‚úÖ ATR calculated",
                    symbols_success=atr_result.get("symbols_success", 0),
                    symbols_failed=atr_result.get("symbols_failed", 0)
                )
            
            logger.info("üéâ Redis recovery completed successfully")
            
            return {
                "success": True,
                "tasks_executed": list(results.keys()),
                "task_results": results
            }
        
        except Exception as e:
            logger.error("recovery_execution_failed", error=str(e))
            return {
                "success": False,
                "error": str(e),
                "partial_results": results
            }

