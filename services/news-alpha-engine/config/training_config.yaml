# ============================================
# NEWS ALPHA ENGINE - Training Configuration
# ============================================

# === Project Info ===
project:
  name: "news-alpha-engine"
  version: "1.0.0"
  description: "Financial news impact prediction system"

# === Data Sources ===
data:
  # Historical news from your existing Polygon/Benzinga integration
  news_sources:
    - name: "polygon_benzinga"
      type: "local"
      path: "/data/news/benzinga/"
      format: "parquet"
      
    - name: "fingpt_sentiment"
      type: "huggingface"
      dataset_id: "FinGPT/fingpt-sentiment-train"
      split: "train"
      
    - name: "twitter_financial"
      type: "huggingface" 
      dataset_id: "zeroshot/twitter-financial-news-sentiment"
      split: "train"

  # Price data for CAR calculation
  price_data:
    source: "polygon_flat_files"
    path: "/data/polygon/day/"
    format: "parquet"
    benchmark: "SPY"
    
  # Output paths
  output:
    processed_news: "/data/processed/news_processed.parquet"
    labeled_news: "/data/processed/news_with_labels.parquet"
    train_set: "/data/processed/train.parquet"
    val_set: "/data/processed/val.parquet"
    test_set: "/data/processed/test.parquet"

  # Date ranges
  date_range:
    train_start: "2020-01-01"
    train_end: "2023-06-30"
    val_start: "2023-07-01"
    val_end: "2023-12-31"
    test_start: "2024-01-01"
    test_end: "2024-12-31"

# === CAR Calculation ===
car_calculation:
  # Event windows (days relative to news)
  windows: [1, 3, 5, 10]
  
  # Estimation window for beta calculation
  estimation_window: 60
  
  # Minimum gap between estimation and event
  gap_days: 5
  
  # Filters for valid stocks
  min_price: 1.0
  max_price: 10000.0
  min_avg_volume: 100000
  min_market_cap: 50000000  # $50M
  
  # Abnormal return method: 'market_model', 'market_adjusted', 'mean_adjusted'
  method: "market_model"
  
  # Statistical significance
  min_t_statistic: 1.96  # 95% confidence

# === News Encoder (FinBERT) ===
encoder:
  # Base model from HuggingFace
  base_model: "ProsusAI/finbert"
  
  # Tokenization
  max_length: 512
  truncation: true
  padding: "max_length"
  
  # Training hyperparameters
  learning_rate: 2.0e-5
  weight_decay: 0.01
  batch_size: 16  # Reduced for g5.xlarge (16GB RAM)
  gradient_accumulation_steps: 2  # Effective batch = 32
  epochs: 5
  warmup_ratio: 0.1
  
  # Regularization
  dropout: 0.1
  attention_dropout: 0.1
  
  # Mixed precision
  fp16: true
  
  # Output
  output_dir: "/models/news_encoder"
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  load_best_model_at_end: true
  metric_for_best_model: "f1"

# === Topic Model (BERTopic) ===
topic_model:
  # Use our fine-tuned encoder for embeddings
  embedding_model: "trained_finbert"
  
  # Alternatively, use pre-trained (faster)
  # embedding_model: "all-MiniLM-L6-v2"
  
  # Topic parameters
  min_topic_size: 30
  nr_topics: "auto"  # Let BERTopic decide, or set fixed number
  top_n_words: 10
  
  # UMAP parameters (for dimensionality reduction)
  umap:
    n_components: 5
    n_neighbors: 15
    min_dist: 0.0
    metric: "cosine"
    low_memory: false
  
  # HDBSCAN parameters (for clustering)
  hdbscan:
    min_cluster_size: 30
    min_samples: 10
    metric: "euclidean"
    cluster_selection_method: "eom"
  
  # Guided topics (seed words for specific categories)
  guided_topics:
    - name: "earnings"
      keywords: ["earnings", "revenue", "profit", "EPS", "guidance", "beat", "miss", "quarterly", "annual"]
    - name: "fda_regulatory"
      keywords: ["FDA", "approval", "drug", "clinical", "trial", "phase", "NDA", "BLA", "breakthrough"]
    - name: "dilution"
      keywords: ["dilution", "offering", "shelf", "ATM", "warrant", "conversion", "shares", "registered"]
    - name: "mergers_acquisitions"
      keywords: ["merger", "acquisition", "buyout", "deal", "M&A", "takeover", "bid", "offer"]
    - name: "sec_legal"
      keywords: ["SEC", "filing", "investigation", "lawsuit", "settlement", "subpoena", "fraud"]
    - name: "dividends_buybacks"
      keywords: ["dividend", "buyback", "repurchase", "shareholder", "return", "payout"]
    - name: "contracts"
      keywords: ["contract", "partnership", "agreement", "deal", "award", "signed"]
    - name: "management"
      keywords: ["CEO", "CFO", "executive", "resignation", "appointed", "hire", "depart"]
    - name: "analyst_ratings"
      keywords: ["upgrade", "downgrade", "target", "rating", "analyst", "buy", "sell", "hold"]
    - name: "bankruptcy_restructuring"
      keywords: ["bankruptcy", "chapter", "restructuring", "debt", "default", "creditor"]
  
  # Output
  output_dir: "/models/topic_model"

# === Impact Predictor (Multi-task Neural Network) ===
impact_predictor:
  # Architecture
  architecture: "transformer_mlp"
  
  # Input dimensions (auto-calculated)
  # news_embedding_dim: 768 (from FinBERT)
  # topic_embedding_dim: 32
  # stock_features_dim: ~20
  
  # Hidden layers
  hidden_dims: [512, 256, 128]
  
  # Regularization
  dropout: 0.3
  layer_norm: true
  
  # Training
  learning_rate: 1.0e-4
  weight_decay: 1.0e-5
  batch_size: 64
  epochs: 100
  early_stopping_patience: 10
  
  # Scheduler
  scheduler: "cosine"
  warmup_steps: 500
  
  # Multi-task heads
  tasks:
    - name: "car_1d"
      type: "regression"
      loss: "huber"  # Robust to outliers
      loss_delta: 0.1
      weight: 1.0
      
    - name: "car_5d"
      type: "regression"
      loss: "huber"
      loss_delta: 0.1
      weight: 1.0
      
    - name: "direction"
      type: "classification"
      classes: ["down", "neutral", "up"]
      loss: "focal"  # Handles class imbalance
      focal_gamma: 2.0
      weight: 0.5
      
    - name: "magnitude"
      type: "classification"
      classes: ["low", "medium", "high"]
      loss: "focal"
      focal_gamma: 2.0
      weight: 0.5
      
    - name: "confidence"
      type: "regression"
      loss: "mse"
      weight: 0.3
  
  # Output
  output_dir: "/models/impact_predictor"
  checkpoint_every: 5  # epochs

# === Backtest Configuration ===
backtest:
  # Strategy parameters
  strategy: "threshold"  # threshold, top_n, all
  
  # Entry conditions
  min_predicted_car: 0.02  # 2% minimum expected return
  min_confidence: 0.7
  min_topic_confidence: 0.5
  
  # Position sizing
  initial_capital: 100000
  position_size: 0.1  # 10% per position
  max_positions: 10
  
  # Holding period
  default_holding_days: 5
  
  # Costs
  slippage: 0.001  # 0.1%
  commission: 0.0  # Assuming commission-free
  
  # Risk management
  stop_loss: 0.05  # 5%
  take_profit: null  # No take profit by default
  
  # Market regime filter
  use_market_regime: true
  vix_threshold_high: 30  # Reduce position size when VIX > 30
  
  # Output
  output_dir: "/data/backtest_results"

# === Experiment Tracking ===
tracking:
  # Weights & Biases
  wandb:
    enabled: true
    project: "news-alpha-engine"
    entity: null  # Your wandb username
    tags: ["finbert", "bertopic", "news-impact"]
  
  # Local logging
  log_dir: "/logs"
  log_level: "INFO"

# === Hardware ===
hardware:
  # GPU settings
  device: "cuda"
  precision: "fp16"  # fp16, bf16, fp32
  
  # DataLoader
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2
  
  # Memory optimization
  gradient_checkpointing: true
  empty_cache_freq: 100  # Clear GPU cache every N batches

# === Reproducibility ===
seed: 42
deterministic: true

