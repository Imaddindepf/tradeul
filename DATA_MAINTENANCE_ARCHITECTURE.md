# ðŸ”§ Data Maintenance Architecture

## ðŸ“‹ Resumen

El **Data Maintenance Service** es un servicio dedicado y autÃ³nomo que se encarga de todas las tareas de mantenimiento de datos histÃ³ricos, ejecutÃ¡ndose automÃ¡ticamente al cierre del mercado cada dÃ­a.

---

## ðŸŽ¯ Problema que Resuelve

**Antes**: La carga de datos estaba dispersa entre mÃºltiples servicios:

- `Historical`: Warmup de metadata (market cap, float, sector)
- Scripts manuales: OHLC para ATR, volume slots para RVOL
- Sin automatizaciÃ³n consistente
- Sin tolerancia a fallos
- Sin coordinaciÃ³n entre tareas

**Ahora**: Un solo servicio centralizado que:

- âœ… Ejecuta **automÃ¡ticamente** al cierre del mercado
- âœ… **Tolerante a fallos**: Reanuda donde quedÃ³ si se reinicia
- âœ… **Coordinado**: Ejecuta tareas en orden lÃ³gico
- âœ… **Monitoreable**: Logs estructurados + endpoints de estado
- âœ… **Independiente**: No sobrecarga otros servicios

---

## ðŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA MAINTENANCE SERVICE                    â”‚
â”‚                   (Puerto 8008, Siempre activo)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚                  â”‚
         â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Maintenance     â”‚ â”‚     Task     â”‚ â”‚  Individual   â”‚
â”‚   Scheduler     â”‚ â”‚ Orchestrator â”‚ â”‚    Tasks      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
         â”‚                  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚         â”‚                 â”‚
         â”‚                  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚                  â”‚    â”‚ OHLC    â”‚     â”‚ Volume   â”‚
         â”‚                  â”‚    â”‚ Daily   â”‚     â”‚ Slots    â”‚
         â”‚                  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚         â”‚                 â”‚
         â”‚                  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚                  â”‚    â”‚Metadata â”‚     â”‚  Redis   â”‚
         â”‚                  â”‚    â”‚ Enrich  â”‚     â”‚  Sync    â”‚
         â”‚                  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚
         â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MARKET SESSION MONITOR              â”‚
â”‚  - Detecta: MARKET_OPEN â†’ POST_MARKET â†’ CLOSED  â”‚
â”‚  - Trigger: 17:00 ET (1h despuÃ©s del cierre)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â° Flujo de EjecuciÃ³n

### **1. Monitoreo Continuo**

```
Scheduler ejecuta loop cada 60 segundos:
â”œâ”€ Obtener hora actual en ET (America/New_York)
â”œâ”€ Determinar sesiÃ³n: PRE_MARKET | MARKET_OPEN | POST_MARKET | CLOSED
â””â”€ Si es 17:00 ET y dÃ­a de semana â†’ Ejecutar mantenimiento
```

### **2. EjecuciÃ³n de Mantenimiento**

```
17:00 ET - INICIO
â”‚
â”œâ”€ [1] Load OHLC Daily (5-10 min)
â”‚   â”œâ”€ Obtener sÃ­mbolos activos de ticker_universe
â”‚   â”œâ”€ Cargar Ãºltimos 30 dÃ­as de OHLC desde Polygon
â”‚   â”œâ”€ Insertar/actualizar en market_data_daily
â”‚   â””â”€ âœ… Completado
â”‚
â”œâ”€ [2] Load Volume Slots (3-5 min)
â”‚   â”œâ”€ Cargar Ãºltimos 10 dÃ­as de agregados 1-min desde Polygon
â”‚   â”œâ”€ Convertir a slots de 5 minutos
â”‚   â”œâ”€ Insertar/actualizar en volume_slots
â”‚   â””â”€ âœ… Completado
â”‚
â”œâ”€ [3] Enrich Metadata (10-15 min)
â”‚   â”œâ”€ Identificar sÃ­mbolos sin metadata o desactualizados
â”‚   â”œâ”€ Obtener market cap, float, sector, industry desde Polygon
â”‚   â”œâ”€ Insertar/actualizar en ticker_metadata
â”‚   â””â”€ âœ… Completado
â”‚
â”œâ”€ [4] Sync Redis (1-2 min)
â”‚   â”œâ”€ Sincronizar metadata a Redis (ticker:metadata:{symbol})
â”‚   â”œâ”€ Calcular y actualizar promedios de volumen
â”‚   â”œâ”€ Limpiar caches obsoletos
â”‚   â””â”€ âœ… Completado
â”‚
â””â”€ 17:30 ET - FINALIZADO
    â”œâ”€ Guardar estado en Redis: maintenance:last_run = 2025-11-11
    â”œâ”€ Log con estadÃ­sticas completas
    â””â”€ Esperar al prÃ³ximo dÃ­a
```

### **3. Tolerancia a Fallos**

```
Redis Tracking:
maintenance:status:2025-11-11 = {
  "date": "2025-11-11",
  "started_at": "2025-11-11T17:00:00Z",
  "tasks": {
    "ohlc_daily": "completed",
    "volume_slots": "completed",
    "metadata_enrich": "in_progress",  â† Se cayÃ³ aquÃ­
    "redis_sync": "pending"
  }
}

Al reiniciar:
1. Leer estado desde Redis
2. Identificar Ãºltima tarea completada
3. Reanudar desde "metadata_enrich"
4. NO repetir "ohlc_daily" ni "volume_slots"
```

---

## ðŸ“Š Tareas en Detalle

### **1. LoadOHLCTask**

**PropÃ³sito**: Cargar OHLC diario para cÃ¡lculo de ATR (Average True Range)

**Fuente**: Polygon API `v2/aggs/ticker/{symbol}/range/1/day/{start}/{end}`

**Destino**: TimescaleDB `market_data_daily` (hypertable)

**Datos**:

- `date`, `symbol`
- `open`, `high`, `low`, `close`
- `volume`, `vwap`, `trades_count`

**Ventana**: Ãšltimos 30 dÃ­as (para ATR-14)

**Tasa de requests**: Max 10 concurrentes (Polygon rate limit)

---

### **2. LoadVolumeSlotsTask**

**PropÃ³sito**: Cargar volume slots de 5 minutos para cÃ¡lculo de RVOL (Relative Volume)

**Fuente**: Polygon API `v2/aggs/ticker/{symbol}/range/1/minute/{date}/{date}`

**Proceso**:

1. Obtener agregados de 1 minuto
2. Agrupar en slots de 5 minutos
3. Calcular slot_index (0-191 para extended hours)

**Destino**: TimescaleDB `volume_slots` (hypertable)

**Datos**:

- `date`, `symbol`, `slot_index`
- `volume` (acumulado para el slot)

**Ventana**: Ãšltimos 10 dÃ­as

**Tasa de requests**: Max 10 concurrentes

---

### **3. EnrichMetadataTask**

**PropÃ³sito**: Enriquecer metadata financiera de tickers

**Fuente**: Polygon API `v3/reference/tickers/{symbol}`

**Destino**: TimescaleDB `ticker_metadata`

**Datos**:

- `market_cap`: CapitalizaciÃ³n de mercado
- `float_shares`: Float (acciones disponibles)
- `shares_outstanding`: Acciones totales
- `sector`: Sector econÃ³mico (e.g., Technology)
- `industry`: Industria especÃ­fica (e.g., Software)
- `description`: DescripciÃ³n de la empresa

**Criterios de prioridad**:

1. Tickers sin `market_cap`
2. Tickers sin `sector`
3. Metadata actualizada hace > 7 dÃ­as

**LÃ­mite**: 500 sÃ­mbolos por ejecuciÃ³n (prioriza mÃ¡s importantes)

**Tasa de requests**: Max 5 concurrentes + 200ms delay (rate limit estricto)

---

### **4. SyncRedisTask**

**PropÃ³sito**: Sincronizar caches de Redis con datos actualizados de TimescaleDB

**Operaciones**:

1. **Sincronizar Metadata**:

   ```
   ticker:metadata:{symbol} = {
     "market_cap": 50000000000,
     "float_shares": 100000000,
     "sector": "Technology",
     ...
   }
   TTL: 24 horas
   ```

2. **Sincronizar Promedios de Volumen**:

   ```
   ticker:avg_volume:{symbol} = {
     "avg_volume_30d": 5000000,
     "avg_volume_10d": 6000000,
     "avg_volume_5d": 7000000
   }
   TTL: 24 horas
   ```

3. **Limpiar Caches Obsoletos**:
   - Eliminar metadata de tickers inactivos
   - Eliminar keys huÃ©rfanos

**Beneficio**: Lecturas ultrarrÃ¡pidas en runtime (Redis vs PostgreSQL)

---

## ðŸ”— IntegraciÃ³n con Otros Servicios

### **Historical Service**

- **ANTES**: Ejecutaba warmup automÃ¡tico de metadata al cierre
- **AHORA**: Solo SIRVE datos a travÃ©s de endpoints (read-only)
- **Cambio**: Warmup automÃ¡tico desactivado, delegado a `data_maintenance`

```python
# Historical solo sirve datos:
GET /api/metadata/{symbol}        # Lee de Redis/TimescaleDB
GET /api/metadata/bulk?symbols=...  # Batch read
POST /api/warmup                   # Manual trigger (testing only)
```

### **Analytics Service**

- **No cambia**: Ya usa datos de TimescaleDB sin cargarlos
- **Beneficio**: Datos siempre actualizados para cÃ¡lculos de RVOL, ATR

### **Scanner Service**

- **No cambia**: Lee metadata desde Historical endpoints
- **Beneficio**: Metadata actualizada para filtros (market cap, sector)

---

## ðŸ›¡ï¸ Tolerancia a Fallos

### **Escenarios Cubiertos**

1. **Servicio se cae durante ejecuciÃ³n**:

   - Estado guardado en Redis despuÃ©s de cada tarea
   - Al reiniciar: Lee estado, continÃºa desde Ãºltima tarea pendiente

2. **Tarea individual falla**:

   - Marca como `failed`, continÃºa con las demÃ¡s
   - Log detallado del error
   - Reporte final indica Ã©xito parcial

3. **Rate limiting de Polygon**:

   - Semaphores para limitar concurrencia
   - Delays configurables entre requests
   - Retry automÃ¡tico si falla (max 3 intentos)

4. **ConexiÃ³n a BD se pierde**:

   - Excepciones capturadas
   - Log estructurado
   - Tarea marcada como `failed`
   - Resto de tareas continÃºa

5. **Servicio se reinicia antes de ejecutar**:
   - Al arrancar, NO ejecuta nada inmediatamente
   - Espera hasta las 17:00 ET del dÃ­a siguiente
   - Si detecta que falta mantenimiento de ayer â†’ ejecuta inmediatamente

---

## ðŸ“Š Monitoreo

### **Logs Estructurados**

```json
{
  "event": "maintenance_cycle_finished",
  "date": "2025-11-11",
  "duration_seconds": 1114.5,
  "duration_human": "18.6m",
  "completed": 4,
  "failed": 0,
  "total": 4,
  "success": true
}

{
  "event": "task_completed",
  "task": "ohlc_daily",
  "duration_seconds": 340,
  "symbols_processed": 8543,
  "records_inserted": 256290
}
```

### **Health Endpoints**

```bash
# Health check (Docker healthcheck)
curl http://localhost:8008/health
{
  "status": "healthy",
  "service": "data_maintenance",
  "redis": "connected",
  "timescaledb": "connected",
  "last_maintenance": "2025-11-11",
  "scheduler_running": true
}

# Estado detallado
curl http://localhost:8008/status
{
  "status": "ok",
  "last_maintenance": "2025-11-11",
  "details": {
    "date": "2025-11-11",
    "started_at": "2025-11-11T17:00:00Z",
    "completed_at": "2025-11-11T17:18:34Z",
    "duration_seconds": 1114.5,
    "all_success": true,
    "tasks": {
      "ohlc_daily": "completed",
      "volume_slots": "completed",
      "metadata_enrich": "completed",
      "redis_sync": "completed"
    }
  }
}

# Trigger manual (testing)
curl -X POST http://localhost:8008/trigger
{
  "status": "triggered",
  "message": "Maintenance cycle started"
}
```

### **Redis Keys**

```bash
# Ãšltima ejecuciÃ³n
redis-cli GET maintenance:last_run
# Output: "2025-11-11"

# Estado detallado
redis-cli GET maintenance:status:2025-11-11
# Output: JSON con estado completo

# Listar todos los estados histÃ³ricos
redis-cli KEYS "maintenance:status:*"
```

---

## ðŸš€ Deployment

### **Iniciar Servicio**

```bash
# Build + start
docker compose up -d data_maintenance

# Ver logs
docker logs -f tradeul_data_maintenance

# O usar script helper
./start-data-maintenance.sh
```

### **Verificar Estado**

```bash
# Health check
curl http://localhost:8008/health | jq

# Estado detallado
curl http://localhost:8008/status | jq

# Logs en tiempo real
docker logs -f tradeul_data_maintenance --tail 100
```

### **Testing Manual**

```bash
# Ejecutar mantenimiento inmediatamente (sin esperar al cierre)
curl -X POST http://localhost:8008/trigger

# Monitorear progreso
watch -n 2 'curl -s http://localhost:8008/status | jq'
```

---

## âš™ï¸ ConfiguraciÃ³n

### **Variables de Entorno**

```yaml
# docker-compose.yml
environment:
  - TIMEZONE=America/New_York # Zona horaria para scheduler
  - MAINTENANCE_SCHEDULE=MARKET_CLOSE # Horario de ejecuciÃ³n
  - REDIS_HOST=redis
  - TIMESCALE_HOST=timescale
  - POLYGON_API_KEY=${POLYGON_API_KEY}
```

### **Ajustar Horario**

Por defecto ejecuta a las **17:00 ET** (1 hora despuÃ©s del cierre). Para cambiar:

```python
# services/data_maintenance/maintenance_scheduler.py
self.maintenance_hour = 17  # Cambiar a hora deseada (ET)
self.maintenance_minute = 0
```

### **Ajustar Rate Limits**

Si Polygon limita requests, reducir concurrencia:

```python
# En cada task (load_ohlc.py, load_volume_slots.py, etc.)
semaphore = asyncio.Semaphore(5)  # Reducir de 10 a 5
```

---

## ðŸ§¹ Mantenimiento

### **Limpiar Estados Antiguos**

Redis acumula estados histÃ³ricos (TTL 7 dÃ­as). Para limpiar manualmente:

```bash
# Eliminar estados de mÃ¡s de 7 dÃ­as
redis-cli KEYS "maintenance:status:*" | grep "2024-" | xargs redis-cli DEL

# O todo
redis-cli DEL $(redis-cli KEYS "maintenance:status:*")
```

### **Re-ejecutar Mantenimiento**

Si una tarea fallÃ³ o necesitas actualizar datos:

```bash
# Trigger manual
curl -X POST http://localhost:8008/trigger

# Verificar progreso
curl http://localhost:8008/status | jq '.details.tasks'
```

### **Debugging**

```bash
# Ver logs completos
docker logs tradeul_data_maintenance --since 1h

# Ver solo errores
docker logs tradeul_data_maintenance 2>&1 | grep -i error

# Conectar a Redis para ver estado
docker exec -it tradeul_redis redis-cli
127.0.0.1:6379> GET maintenance:last_run
127.0.0.1:6379> GET maintenance:status:2025-11-11
```

---

## ðŸ“ˆ Beneficios

### **1. CentralizaciÃ³n**

- âœ… Una sola responsabilidad: mantenimiento de datos
- âœ… CÃ³digo limpio y mantenible
- âœ… FÃ¡cil de testear y debuggear

### **2. AutomatizaciÃ³n**

- âœ… Se ejecuta automÃ¡ticamente sin intervenciÃ³n manual
- âœ… Tolerante a fallos
- âœ… No requiere cron jobs externos

### **3. Observabilidad**

- âœ… Logs estructurados con contexto completo
- âœ… Endpoints de health y status
- âœ… Estado persistente en Redis

### **4. Escalabilidad**

- âœ… ParalelizaciÃ³n interna (semaphores)
- âœ… Rate limiting configurable
- âœ… Puede ejecutarse en servidor dedicado

### **5. Independencia**

- âœ… No sobrecarga otros servicios
- âœ… No compite por recursos CPU/RAM
- âœ… Puede reiniciarse sin afectar otros servicios

---

## ðŸ”® Futuro

### **Mejoras Potenciales**

1. **Notificaciones**:

   - Alertas Slack/Email si mantenimiento falla
   - Webhook al completar

2. **Dashboard**:

   - UI simple con estado visual
   - HistÃ³rico de ejecuciones

3. **MÃ©tricas**:

   - Prometheus metrics endpoint
   - Grafana dashboards

4. **Scheduling Avanzado**:

   - MÃºltiples horarios (pre-market + after hours)
   - Diferentes ventanas por tarea

5. **PriorizaciÃ³n Inteligente**:
   - Metadata solo para tickers activos en scanner
   - Skip tickers con volumen = 0

---

## ðŸ“š Referencias

- **CÃ³digo**: `services/data_maintenance/`
- **Docker**: `docker-compose.yml` (servicio `data_maintenance`)
- **DocumentaciÃ³n**: `services/data_maintenance/README.md`
- **Market Session**: `shared/enums/market_session.py`
