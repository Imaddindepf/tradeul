# FASE 3: Migraci√≥n de Microservicios a tickers_unified

**Fecha**: 2025-11-23  
**Estado**: En progreso  
**Objetivo**: Adaptar todos los microservicios y scripts para usar `tickers_unified` directamente

---

## üìä AN√ÅLISIS DE IMPACTO

### ‚úÖ ESTADO ACTUAL (Post FASE 1 y 2)
- `tickers_unified` creada con **35 campos** (20 base + 15 expandidos)
- **12,369 registros** migrados correctamente
- Vistas `ticker_metadata` y `ticker_universe` funcionando como capas de compatibilidad
- **0 downtime** - Todos los servicios funcionan sin cambios

### üéØ OBJETIVO FASE 3
- Eliminar dependencias de las vistas
- Usar `tickers_unified` directamente en todos los servicios
- Deprecar tablas antiguas (`ticker_metadata_old`, `ticker_universe_old`)
- Limpiar Redis y forzar re-sincronizaci√≥n completa

---

## üìã ARCHIVOS IDENTIFICADOS (29 archivos)

### üî¥ **CR√çTICOS - Servicios en producci√≥n**

#### 1. **ticker-metadata-service** (Puerto 8010)
- `services/ticker-metadata-service/metadata_manager.py`
  - **L√≠nea 258**: `SELECT * FROM ticker_metadata WHERE symbol = $1`
  - **L√≠nea 271**: `INSERT INTO ticker_metadata (...) VALUES (...)`
  - **Impacto**: Alto - Servicio principal de metadata
  - **Acci√≥n**: Cambiar a `tickers_unified`

#### 2. **scanner** (Puerto 8001)
- `services/scanner/scanner_engine.py`
  - **Uso indirecto** v√≠a `TimescaleClient.get_ticker_metadata()`
  - **Impacto**: Medio - Usa el cliente gen√©rico
  - **Acci√≥n**: Actualizar `TimescaleClient`

#### 3. **shared/utils/timescale_client.py**
- **L√≠nea 278**: `SELECT * FROM ticker_metadata WHERE symbol = $1`
- **L√≠nea 290**: `INSERT INTO ticker_metadata (...)`
- **Impacto**: CR√çTICO - Usado por TODOS los servicios
- **Acci√≥n**: Cambiar m√©todos a `tickers_unified`

### üü° **IMPORTANTES - Data Maintenance**

#### 4. **data_maintenance** (Puerto 8007)
- `tasks/sync_redis.py` - Sincroniza metadata a Redis
- `tasks/load_ohlc.py` - Carga datos hist√≥ricos
- `tasks/enrich_metadata.py` - Enriquece metadata desde Polygon
- `tasks/calculate_atr.py` - Calcula ATR
- `tasks/calculate_rvol_averages.py` - Calcula RVOL
- `tasks/auto_recover_missing_tickers.py` - Recupera tickers faltantes
- `tasks/load_volume_slots.py` - Carga slots de volumen
- `redis_health_checker.py` - Monitoreo de Redis
- `realtime_ticker_monitor.py` - Monitor en tiempo real
- **Impacto**: Medio-Alto - Tareas programadas
- **Acci√≥n**: Cambiar queries a `tickers_unified`

#### 5. **historical** (Puerto 8004)
- `ticker_universe_loader.py` - **USA `ticker_universe`** üö®
- `historical_loader.py` - Carga datos hist√≥ricos
- `polygon_data_loader.py` - Obtiene datos de Polygon
- `main.py` - Entry point
- **Impacto**: Alto - Manejo de ticker universe
- **Acci√≥n**: Cambiar `ticker_universe` a `tickers_unified`

#### 6. **dilution-tracker** (Puerto 8009)
- `services/sec_dilution_service.py`
- `strategies/tier_manager.py`
- `services/data_aggregator.py`
- `routers/analysis_router.py`
- **Impacto**: Medio - An√°lisis de diluci√≥n
- **Acci√≥n**: Verificar y actualizar queries

### üü¢ **SCRIPTS DE MANTENIMIENTO**

#### 7. **Scripts**
- `scripts/sync_redis_safe.py` - **L√≠nea 31**: `SELECT * FROM ticker_metadata` üö®
- `scripts/populate_cik.py` - Popula CIK desde SEC
- `scripts/load_massive_parallel.py` - Carga masiva paralela
- `scripts/populate_basic_metadata.py` - Popula metadata b√°sica
- `scripts/load_universe_polygon.py` - Carga universe desde Polygon
- `scripts/verify_historical_data.py` - Verifica datos hist√≥ricos
- `scripts/repopulate_metadata.py` - Repopula metadata
- **Impacto**: Bajo - Scripts manuales
- **Acci√≥n**: Actualizar todos los queries

---

## üöÄ PLAN DE EJECUCI√ìN

### **FASE 3.1: Componentes Compartidos** ‚è±Ô∏è 15 min
1. ‚úÖ Actualizar `shared/utils/timescale_client.py`
   - Cambiar `get_ticker_metadata()` a `tickers_unified`
   - Cambiar `upsert_ticker_metadata()` a `tickers_unified`
   - Agregar m√©todo `get_ticker_by_symbol()` gen√©rico

### **FASE 3.2: Servicios Cr√≠ticos** ‚è±Ô∏è 30 min
2. ‚úÖ Actualizar `ticker-metadata-service`
   - `metadata_manager.py`: Cambiar todas las queries
   - Probar endpoints `/api/v1/metadata/{symbol}`

3. ‚úÖ Actualizar `scanner`
   - Verificar que usa `TimescaleClient` actualizado
   - No requiere cambios directos

### **FASE 3.3: Historical Service** ‚è±Ô∏è 20 min
4. ‚úÖ Actualizar `historical/ticker_universe_loader.py`
   - **CR√çTICO**: Cambiar `ticker_universe` a `tickers_unified`
   - Actualizar l√≥gica de carga

### **FASE 3.4: Data Maintenance** ‚è±Ô∏è 25 min
5. ‚úÖ Actualizar `data_maintenance/tasks/`
   - `sync_redis.py`: **CR√çTICO** - Sincronizaci√≥n completa
   - `enrich_metadata.py`: Cambiar queries
   - Resto de tasks: Verificar y actualizar

### **FASE 3.5: Scripts** ‚è±Ô∏è 15 min
6. ‚úÖ Actualizar todos los scripts
   - `sync_redis_safe.py`: **PRIORIDAD 1**
   - Resto de scripts de populate y verify

### **FASE 3.6: Redis Flush** ‚è±Ô∏è 10 min
7. ‚úÖ Vaciar Redis y re-sincronizar
   - Backup de Redis actual
   - FLUSHDB de database 0 (metadata, cache)
   - Ejecutar `sync_redis_safe.py` con datos de `tickers_unified`
   - Verificar keys sincronizadas

### **FASE 3.7: Verificaci√≥n** ‚è±Ô∏è 20 min
8. ‚úÖ Pruebas completas
   - Verificar ticker-metadata-service
   - Verificar scanner (tablas en frontend)
   - Verificar dilution-tracker
   - Verificar logs de errores

---

## üîÑ ESTRATEGIA DE ROLLBACK

Si algo falla durante la migraci√≥n:

```sql
-- 1. Revertir vistas a tablas antiguas
DROP VIEW IF EXISTS ticker_metadata CASCADE;
DROP VIEW IF EXISTS ticker_universe CASCADE;

ALTER TABLE ticker_metadata_old RENAME TO ticker_metadata;
ALTER TABLE ticker_universe_old RENAME TO ticker_universe;

-- 2. Restaurar Redis desde backup
-- (usar script de restauraci√≥n)

-- 3. Reiniciar servicios
docker-compose restart ticker-metadata-service scanner data-maintenance
```

---

## ‚úÖ CRITERIOS DE √âXITO

- [ ] Todos los servicios usan `tickers_unified` directamente
- [ ] No hay errores en logs de servicios
- [ ] Frontend muestra tablas correctamente
- [ ] Redis tiene todos los metadata sincronizados
- [ ] Queries de metadata son m√°s r√°pidas (sin overhead de vistas)
- [ ] Dilution Tracker funciona correctamente
- [ ] Scripts de mantenimiento funcionan

---

## üìä TIEMPO ESTIMADO TOTAL

- **Desarrollo**: ~2 horas
- **Testing**: ~30 minutos
- **Despliegue**: ~15 minutos
- **TOTAL**: ~2.75 horas

---

## üéØ PR√ìXIMOS PASOS (Post-FASE 3)

### FASE 4: Limpieza (Opcional, post-verificaci√≥n)
- Eliminar tablas antiguas (`ticker_metadata_old`, `ticker_universe_old`)
- Eliminar vistas de compatibilidad
- Optimizar √≠ndices en `tickers_unified`
- Agregar Foreign Keys desde otras tablas

---

**Preparado por**: AI Assistant  
**Revisado por**: [Pendiente]  
**Aprobado por**: [Pendiente]

