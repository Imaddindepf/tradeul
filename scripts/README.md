# ğŸ“ Scripts - Herramientas de Mantenimiento

Esta carpeta contiene scripts Ãºtiles para operaciones manuales y de emergencia.

## âš™ï¸ **Scripts de ProducciÃ³n**

### âœ… **init_db.sql**
**PropÃ³sito:** InicializaciÃ³n de esquema de base de datos

```bash
# Se ejecuta automÃ¡ticamente en docker-compose al iniciar TimescaleDB
# Crea todas las tablas: volume_slots, market_data_daily, ticker_universe, etc.
```

**CuÃ¡ndo usar:** Setup inicial o reset completo de BD

---

### âœ… **setup.sh**
**PropÃ³sito:** Script de setup inicial del sistema completo

```bash
./scripts/setup.sh
```

**CuÃ¡ndo usar:** Primera instalaciÃ³n del sistema

---

## ğŸš¨ **Scripts de Emergencia**

### ğŸ”¥ **load_massive_parallel.py**
**PropÃ³sito:** Carga masiva ultra-rÃ¡pida de `volume_slots` (12K+ tickers)

```bash
docker exec tradeul_data_maintenance python /app/scripts/load_massive_parallel.py
```

**CaracterÃ­sticas:**
- Concurrencia masiva: 1000 tickers simultÃ¡neos
- Velocidad: ~100 tickers/segundo
- DetecciÃ³n automÃ¡tica de dÃ­as faltantes
- Solo carga dÃ­as que NO existen en BD

**CuÃ¡ndo usar:**
- Re-poblaciÃ³n completa de `volume_slots`
- RecuperaciÃ³n de datos despuÃ©s de pÃ©rdida
- Carga inicial de histÃ³rico
- **NO usar** para mantenimiento diario (usa `data_maintenance`)

**Tiempo estimado:** ~2-3 minutos para 12K tickers Ã— 10 dÃ­as

---

### ğŸ“Š **load_universe_polygon.py**
**PropÃ³sito:** Cargar universo completo de tickers desde Polygon

```bash
docker exec tradeul_historical python /app/scripts/load_universe_polygon.py
```

**CuÃ¡ndo usar:**
- ActualizaciÃ³n manual del universo
- Agregar nuevos tickers listados
- **Alternativa:** `POST http://localhost:8004/api/universe/load` (recomendado)

---

### ğŸ”„ **repopulate_metadata.py**
**PropÃ³sito:** Re-poblar metadata de tickers (market cap, float, sector)

```bash
docker exec tradeul_historical python /app/scripts/repopulate_metadata.py
```

**CuÃ¡ndo usar:**
- ActualizaciÃ³n masiva de metadata
- DespuÃ©s de cambios en Polygon/FMP APIs
- **Alternativa:** `POST http://localhost:8004/api/warmup/premarket` (recomendado)

---

## ğŸ” **Scripts de VerificaciÃ³n**

### âœ… **verify_historical_data.py**
**PropÃ³sito:** Verificar integridad de datos histÃ³ricos

```bash
docker exec tradeul_data_maintenance python /app/scripts/verify_historical_data.py
```

**QuÃ© verifica:**
- Fechas faltantes en `volume_slots`
- Fechas faltantes en `market_data_daily`
- Inconsistencias en datos
- Gaps en histÃ³rico

**CuÃ¡ndo usar:**
- DespuÃ©s de mantenimiento
- Troubleshooting de datos
- AuditorÃ­as periÃ³dicas

---

### ğŸ”§ **sync_universe_only.py**
**PropÃ³sito:** Sincronizar `ticker_universe` BD â†’ Redis sin ejecutar todo el mantenimiento

```bash
docker exec tradeul_data_maintenance python -c "
import asyncio
import sys
sys.path.append('/app')
from shared.utils.redis_client import RedisClient
from shared.utils.timescale_client import TimescaleClient

async def sync():
    redis = RedisClient()
    db = TimescaleClient()
    await redis.connect()
    await db.connect()
    rows = await db.fetch('SELECT symbol FROM ticker_universe WHERE is_active = true')
    symbols = [row['symbol'] for row in rows]
    await redis.client.delete('ticker:universe')
    for i in range(0, len(symbols), 1000):
        batch = symbols[i:i + 1000]
        if batch:
            await redis.client.sadd('ticker:universe', *batch)
    after = await redis.client.scard('ticker:universe')
    print(f'âœ… Sincronizado: {after} sÃ­mbolos')
    await redis.disconnect()
    await db.disconnect()

asyncio.run(sync())
"
```

**CuÃ¡ndo usar:**
- Corregir desincronizaciÃ³n BD/Redis
- DespuÃ©s de actualizar `ticker_universe` manualmente

---

## âŒ **Scripts Eliminados (Redundantes)**

Los siguientes scripts fueron eliminados porque `data_maintenance` los hace automÃ¡ticamente:

- ~~audit_auto_refresh_system.py~~ â†’ `data_maintenance` auto-ejecuta
- ~~bulk_update_metadata.py~~ â†’ `EnrichMetadataTask`
- ~~cache_metadata_to_redis.py~~ â†’ `SyncRedisTask`
- ~~check_daily_reset.py~~ â†’ `MaintenanceScheduler`
- ~~load_atr_massive.py~~ â†’ `CalculateATRTask`
- ~~load_daily_ohlc.py~~ â†’ `LoadOHLCTask`
- ~~update_all_historical_data.sh~~ â†’ `data_maintenance`
- ~~update_all_metadata.py~~ â†’ `EnrichMetadataTask`
- ~~update_metadata_parallel.py~~ â†’ `EnrichMetadataTask`
- ~~update_metadata_simple.sh~~ â†’ `data_maintenance`

---

## ğŸ“‹ **CuÃ¡ndo Usar Scripts vs Services**

### âœ… **Usa Services (AutomÃ¡tico)**

```bash
# Mantenimiento diario automÃ¡tico
# NO necesitas ejecutar nada, se hace solo cada noche
data_maintenance â†’ Ejecuta TODAS las tareas automÃ¡ticamente
```

### ğŸ”§ **Usa Scripts (Manual/Emergencia)**

| SituaciÃ³n | Script |
|-----------|--------|
| **PÃ©rdida de datos completa** | `load_massive_parallel.py` |
| **Universo desactualizado** | `load_universe_polygon.py` o API |
| **Metadata faltante** | `repopulate_metadata.py` o API |
| **Verificar integridad** | `verify_historical_data.py` |
| **DesincronizaciÃ³n BD/Redis** | `sync_universe_only.py` |
| **Setup inicial** | `setup.sh` |

---

## ğŸ¯ **Regla General**

**99% del tiempo:** `data_maintenance` se encarga de todo automÃ¡ticamente.

**1% del tiempo:** Scripts manuales para casos especiales (emergencias, verificaciÃ³n, re-poblaciÃ³n).

**NO ejecutar scripts de carga si `data_maintenance` estÃ¡ funcionando correctamente.**



