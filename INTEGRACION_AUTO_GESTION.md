# üîß GU√çA DE INTEGRACI√ìN: AUTO-GESTI√ìN DE MEMORIA

## RESUMEN

Esta gu√≠a explica c√≥mo integrar las soluciones autom√°ticas de gesti√≥n de memoria en cada servicio.

**Lo que hemos creado:**
1. ‚úÖ **Migration SQL**: Configura TimescaleDB autom√°ticamente (retenci√≥n, compresi√≥n, aggregates)
2. ‚úÖ **RedisStreamManager**: Gestiona streams con l√≠mites autom√°ticos
3. ‚úÖ **SnapshotManager**: Reemplaza snapshots de 9MB por deltas de 50-200KB

**Todo es AUTOM√ÅTICO**: Una vez integrado, el sistema se auto-gestiona sin intervenci√≥n manual.

---

## üìÅ ARCHIVOS CREADOS

```
migrations/
  ‚îî‚îÄ‚îÄ 004_optimize_memory_usage.sql       # ‚Üê Ejecutar UNA VEZ

shared/utils/
  ‚îú‚îÄ‚îÄ redis_stream_manager.py             # ‚Üê Auto-trimming de streams
  ‚îî‚îÄ‚îÄ snapshot_manager.py                 # ‚Üê Snapshots con deltas
```

---

## üöÄ PASO 1: EJECUTAR MIGRATION (UNA SOLA VEZ)

### Opci√≥n A: Desde Docker (RECOMENDADO)

```bash
cd /Users/imaddinamsif/Desktop/Tradeul-Amsif

# Ejecutar migration
docker exec tradeul_timescale psql \
  -U tradeul_user \
  -d tradeul \
  -f /path/to/004_optimize_memory_usage.sql

# Verificar que se aplic√≥
docker exec tradeul_timescale psql -U tradeul_user -d tradeul -c "
  SELECT hypertable_name, older_than 
  FROM timescaledb_information.jobs 
  WHERE proc_name = 'policy_retention';
"
```

### Opci√≥n B: Copiar y ejecutar manualmente

```bash
# 1. Copiar migration al contenedor
docker cp migrations/004_optimize_memory_usage.sql tradeul_timescale:/tmp/

# 2. Ejecutar
docker exec tradeul_timescale psql \
  -U tradeul_user \
  -d tradeul \
  -f /tmp/004_optimize_memory_usage.sql
```

**Resultado esperado:**
```
‚úÖ Pol√≠ticas de retenci√≥n configuradas
‚úÖ Compresi√≥n autom√°tica habilitada
‚úÖ Continuous aggregates creados
‚úÖ √çndices optimizados
```

---

## üîß PASO 2: INTEGRAR RedisStreamManager EN SERVICIOS

### 2.1 Data Ingest Service

**Archivo:** `services/data_ingest/main.py`

```python
# ============================================
# IMPORTS A√ëADIR
# ============================================
from shared.utils.redis_stream_manager import (
    initialize_stream_manager,
    get_stream_manager
)

# ============================================
# EN LA FUNCI√ìN lifespan (startup)
# ============================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ... c√≥digo existente ...
    
    # Inicializar RedisClient
    redis_client = RedisClient(...)
    await redis_client.connect()
    
    # üî• AGREGAR: Inicializar StreamManager
    stream_manager = initialize_stream_manager(redis_client)
    await stream_manager.start()  # Inicia auto-trimming
    logger.info("stream_manager_started")
    
    yield
    
    # üî• AGREGAR: Detener StreamManager
    await stream_manager.stop()
    logger.info("stream_manager_stopped")

# ============================================
# REEMPLAZAR TODOS LOS redis.xadd POR:
# ============================================

# ANTES:
await redis.xadd("snapshots:raw", {"data": snapshot})

# DESPU√âS:
stream_manager = get_stream_manager()
await stream_manager.xadd("snapshots:raw", {"data": snapshot})

# ¬°Eso es todo! El MAXLEN es autom√°tico
```

### 2.2 Scanner Service

**Archivo:** `services/scanner/scanner_engine.py`

```python
# ============================================
# IMPORTS A√ëADIR AL INICIO
# ============================================
from shared.utils.redis_stream_manager import get_stream_manager

# ============================================
# EN __init__ DEL ScannerEngine
# ============================================
class ScannerEngine:
    def __init__(self, ...):
        # ... c√≥digo existente ...
        self.stream_manager = get_stream_manager()  # Obtener instancia

# ============================================
# ACTUALIZAR emit_full_snapshot (l√≠nea ~1540)
# ============================================
async def emit_full_snapshot(self, list_name: str, tickers: List[ScannerTicker]):
    # ... c√≥digo existente hasta message = {...} ...
    
    # REEMPLAZAR:
    # await self.redis.xadd(
    #     settings.stream_ranking_deltas,
    #     message,
    #     maxlen=20000,  # ‚Üê ESTO ERA HARDCODED
    #     approximate=True
    # )
    
    # POR:
    await self.stream_manager.xadd(
        settings.stream_ranking_deltas,
        message
        # maxlen es autom√°tico seg√∫n config
    )

# ============================================
# ACTUALIZAR emit_ranking_deltas (l√≠nea ~1450)
# ============================================
async def emit_ranking_deltas(self, list_name: str, deltas: List[Dict]):
    # ... c√≥digo existente hasta message = {...} ...
    
    # REEMPLAZAR:
    # await self.redis.xadd(...)
    
    # POR:
    await self.stream_manager.xadd(
        settings.stream_ranking_deltas,
        message
    )
```

### 2.3 Analytics Service

**Archivo:** `services/analytics/main.py`

```python
# Similar al Data Ingest:
# 1. Initialize stream_manager en lifespan
# 2. Reemplazar redis.xadd por stream_manager.xadd
```

---

## üì∏ PASO 3: INTEGRAR SnapshotManager EN SCANNER

### 3.1 Inicializar SnapshotManager

**Archivo:** `services/scanner/scanner_engine.py`

```python
# ============================================
# IMPORTS A√ëADIR
# ============================================
from shared.utils.snapshot_manager import SnapshotManager

# ============================================
# EN __init__ DEL ScannerEngine
# ============================================
class ScannerEngine:
    def __init__(self, redis_client: RedisClient, ...):
        # ... c√≥digo existente ...
        
        # üî• AGREGAR: Snapshot Manager
        self.snapshot_manager = SnapshotManager(
            redis_client=redis_client,
            full_snapshot_interval=300,  # 5 minutos
            delta_compression_threshold=100,
            min_price_change_percent=0.001,  # 0.1%
            min_rvol_change_percent=0.05     # 5%
        )
        
        logger.info("snapshot_manager_initialized")
```

### 3.2 Usar SnapshotManager en lugar de guardar JSON completo

**Archivo:** `services/scanner/scanner_engine.py`

```python
# ============================================
# ACTUALIZAR _save_ranking_to_redis (l√≠nea ~1480)
# ============================================
async def _save_ranking_to_redis(
    self,
    list_name: str,
    tickers: List[ScannerTicker]
):
    """
    Guarda ranking usando snapshot inteligente (full o delta)
    """
    try:
        # Convertir tickers a dict
        ranking_dict = {
            t.symbol: t.model_dump(mode='json')
            for t in tickers
        }
        
        # üî• USAR SNAPSHOT MANAGER en lugar de JSON directo
        result = await self.snapshot_manager.save_snapshot(ranking_dict)
        
        # Guardar sequence number
        current_sequence = self.sequence_numbers.get(list_name, 0)
        await self.redis.set(
            f"scanner:sequence:{list_name}",
            current_sequence,
            ttl=86400
        )
        
        logger.debug(
            "ranking_saved_with_snapshot_manager",
            list=list_name,
            snapshot_type=result["type"],  # "full" o "delta"
            count=len(tickers),
            size_kb=result.get("compressed_size", result.get("size", 0)) / 1024
        )
        
    except Exception as e:
        logger.error("save_ranking_error", error=str(e), list=list_name)
```

### 3.3 Frontend: Consumir Deltas (OPCIONAL, puede esperar)

El frontend actualmente consume snapshots completos. Puede seguir funcionando mientras migras:

```typescript
// frontend/lib/api.ts

// Opci√≥n 1: Obtener snapshot completo (backward compatible)
export async function getFullSnapshot() {
  const res = await fetch(`${API}/snapshot/full/latest`);
  // Descomprimir en backend y retornar JSON
}

// Opci√≥n 2: Obtener delta (nueva funcionalidad)
export async function getSnapshotDelta() {
  const res = await fetch(`${API}/snapshot/delta/latest`);
  // Aplicar delta al estado local
}
```

**Por ahora, puedes seguir usando snapshots completos cada 5 minutos**. El ahorro ya es enorme (9MB ‚Üí 200KB-1MB comprimido).

---

## üìä PASO 4: AGREGAR ENDPOINT DE M√âTRICAS

### 4.1 API Gateway: Endpoint de Monitoreo

**Archivo:** `services/api_gateway/main.py`

```python
from shared.utils.redis_stream_manager import get_stream_manager
from shared.utils.snapshot_manager import SnapshotManager

@app.get("/api/v1/internal/memory-metrics")
async def get_memory_metrics():
    """
    Endpoint interno para monitorear uso de memoria
    """
    try:
        stream_manager = get_stream_manager()
        
        # Stats de streams
        stream_stats = stream_manager.get_stats()
        all_streams = await stream_manager.get_all_streams_info()
        
        # Stats de snapshots (si el scanner expone su snapshot_manager)
        # snapshot_stats = snapshot_manager.get_stats()
        
        return {
            "streams": {
                "stats": stream_stats,
                "details": all_streams
            },
            "timescaledb": {
                "retention_policies": "active",  # Configurado en migration
                "compression": "enabled"          # Autom√°tico cada 2h
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error("memory_metrics_error", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))
```

### 4.2 Verificar M√©tricas

```bash
# Ver m√©tricas de memoria
curl http://localhost:8000/api/v1/internal/memory-metrics | jq

# Resultado esperado:
{
  "streams": {
    "stats": {
      "is_running": true,
      "active_trim_tasks": 5,
      "total_adds": 12450,
      "total_trims": 23,
      "bytes_trimmed": 1250000
    },
    "details": [
      {
        "stream": "snapshots:raw",
        "length": 998,
        "maxlen": 1000,
        "usage_percent": 99.8
      },
      ...
    ]
  }
}
```

---

## ‚úÖ VERIFICACI√ìN POST-INTEGRACI√ìN

### 1. TimescaleDB (despu√©s de 24h)

```sql
-- Verificar que retention est√° funcionando
SELECT 
  hypertable_name,
  COUNT(*) as chunk_count,
  pg_size_pretty(hypertable_size(format('%I.%I', hypertable_schema, hypertable_name)::regclass)) as size
FROM timescaledb_information.hypertables
GROUP BY hypertable_name, hypertable_schema;

-- Deber√≠a ver:
-- scan_results: ~2-3 GB (vs 10 GB antes)
-- Chunks comprimidos despu√©s de 2 horas
```

### 2. Redis Streams

```bash
# Verificar tama√±os de streams
docker exec tradeul_redis redis-cli --scan --pattern "stream:*" | \
  xargs -I {} docker exec tradeul_redis redis-cli XLEN {}

# Deber√≠a ver:
# snapshots:raw: ~1000 (vs 50,003 antes)
# stream:ranking:deltas: ~5000 (vs 20,000 antes)
```

### 3. Redis Memory

```bash
docker exec tradeul_redis redis-cli INFO memory | grep used_memory_human

# Deber√≠a ver:
# used_memory_human: 150-200MB (vs 743MB antes)
```

### 4. Snapshots

```bash
# Ver tama√±o de snapshots
docker exec tradeul_redis redis-cli --bigkeys | grep snapshot

# Deber√≠a ver:
# snapshot:full:latest: ~200KB-1MB comprimido (vs 9MB antes)
# snapshot:delta:latest: ~50-200KB
```

### 5. CPU y RAM General

```bash
docker stats --no-stream

# Deber√≠a ver:
# timescaledb: 100-200% CPU (vs 691% antes)
# redis: 30-50% CPU (vs 156% antes)
# RAM total: ~2.5-3.5 GB (vs 6-16 GB antes)
```

---

## üéØ CHECKLIST DE INTEGRACI√ìN

### Fase 1: Setup Inicial (30 min)
- [ ] Ejecutar migration `004_optimize_memory_usage.sql`
- [ ] Verificar policies activas en TimescaleDB
- [ ] Reiniciar servicios para aplicar configuraci√≥n

### Fase 2: Data Ingest (15 min)
- [ ] Agregar imports de `RedisStreamManager`
- [ ] Inicializar en `lifespan()`
- [ ] Reemplazar `redis.xadd` por `stream_manager.xadd`
- [ ] Verificar logs de auto-trimming

### Fase 3: Scanner (30 min)
- [ ] Agregar imports de ambos managers
- [ ] Inicializar `SnapshotManager`
- [ ] Actualizar `_save_ranking_to_redis`
- [ ] Actualizar `emit_full_snapshot`
- [ ] Actualizar `emit_ranking_deltas`
- [ ] Verificar logs de snapshots (full vs delta)

### Fase 4: Analytics (15 min)
- [ ] Similar a Data Ingest
- [ ] Actualizar streams de RVOL

### Fase 5: Monitoreo (15 min)
- [ ] Agregar endpoint de m√©tricas
- [ ] Verificar con `curl`
- [ ] Monitorear por 24-48 horas

### Fase 6: Validaci√≥n (24-48h)
- [ ] Verificar retenci√≥n autom√°tica funcionando
- [ ] Verificar compresi√≥n aplic√°ndose
- [ ] Verificar streams mantienen l√≠mites
- [ ] Verificar snapshots usando deltas
- [ ] Confirmar RAM estable < 3.5 GB
- [ ] Confirmar CPU estable < 200%

---

## üÜò TROUBLESHOOTING

### Problema: Migration falla con "relation already exists"

**Soluci√≥n:**
```sql
-- Verificar si ya existe
SELECT * FROM timescaledb_information.continuous_aggregates;

-- Si existe, skip esa parte o usar IF NOT EXISTS
```

### Problema: Stream Manager no inicia

**Error:**
```
RedisStreamManager not initialized
```

**Soluci√≥n:**
```python
# Asegurarse de llamar initialize_stream_manager() en lifespan
stream_manager = initialize_stream_manager(redis_client)
await stream_manager.start()  # ‚Üê NO OLVIDAR .start()
```

### Problema: Snapshots siguen siendo grandes

**Verificar:**
```python
# En logs, buscar:
"delta_snapshot_saved"  # Deber√≠a aparecer cada 5s
"full_snapshot_saved"   # Deber√≠a aparecer cada 5 min

# Si solo ves full_snapshot_saved:
# - Verificar que snapshot_manager est√° inicializado
# - Verificar que previous_snapshot no est√° vac√≠o
```

### Problema: Compression policy no funciona

**Verificar:**
```sql
-- Ver jobs de compresi√≥n
SELECT * FROM timescaledb_information.jobs 
WHERE proc_name = 'policy_compression';

-- Ver chunks comprimidos
SELECT 
  chunk_name,
  compressed_chunk_name,
  before_compression_total_bytes,
  after_compression_total_bytes
FROM timescaledb_information.compressed_chunk_stats
LIMIT 10;
```

---

## üìà RESULTADOS ESPERADOS

### D√≠a 0 (Antes):
```
RAM: 6 GB ‚Üí 16 GB en 24h
CPU TimescaleDB: 691%
Redis Memory: 743 MB
scan_results: 10 GB / 12.5M filas
Snapshots: 9 MB cada 5s
```

### D√≠a 1 (Despu√©s de integrar):
```
RAM: 3-4 GB estable
CPU TimescaleDB: 150-200%
Redis Memory: 150-200 MB
scan_results: 2-3 GB / ~2M filas
Snapshots: 50-200 KB deltas, 200KB-1MB full
```

### D√≠a 7 (Estable):
```
RAM: 2.5-3 GB estable
CPU TimescaleDB: 80-150%
Redis Memory: 150 MB estable
scan_results: 2 GB / ~2M filas (3 d√≠as)
Sistema auto-gestionado
```

---

## üéì CONCEPTOS CLAVE

### ¬øPor qu√© funciona?

1. **Retention Policies**: TimescaleDB borra datos > 3 d√≠as AUTOM√ÅTICAMENTE
2. **Compression**: Datos > 2h se comprimen 80-90% AUTOM√ÅTICAMENTE
3. **Continuous Aggregates**: Pre-c√°lculos se mantienen frescos AUTOM√ÅTICAMENTE
4. **Stream Trimming**: Redis limita streams AUTOM√ÅTICAMENTE (inline + background)
5. **Snapshot Deltas**: Solo env√≠a cambios, no datos completos

### ¬øQu√© pasa si falla algo?

- **Retention**: Los datos viejos se mantienen (no se pierden) hasta el pr√≥ximo job
- **Compression**: Chunks sin comprimir funcionan normal (solo ocupan m√°s)
- **Stream Trimming**: Si falla, siguiente trim cleanup corrige
- **Snapshots**: Si falla delta, env√≠a full snapshot (fallback autom√°tico)

**TODO ES RESILIENTE Y AUTO-RECUPERABLE**

---

## üöÄ PR√ìXIMOS PASOS

1. ‚úÖ **Ejecutar migration** ‚Üí 5 min
2. ‚úÖ **Integrar en data_ingest** ‚Üí 15 min
3. ‚úÖ **Integrar en scanner** ‚Üí 30 min
4. ‚úÖ **Integrar en analytics** ‚Üí 15 min
5. ‚úÖ **Agregar m√©tricas** ‚Üí 15 min
6. ‚è≥ **Monitorear 24-48h** ‚Üí validar
7. üéâ **Sistema auto-gestionado permanentemente**

---

**¬øListo para empezar? ¬øPor d√≥nde quieres comenzar?**

