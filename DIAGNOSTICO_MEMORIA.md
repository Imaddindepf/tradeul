# üö® DIAGN√ìSTICO: FUGA DE MEMORIA EN DOCKER

## RESUMEN EJECUTIVO

Tu sistema est√° acumulando datos sin l√≠mites de retenci√≥n, causando:

- **10 GB en TimescaleDB** (scan_results)
- **674 MB en Redis** (streams sin l√≠mite)
- **Crecimiento continuo**: ~1.5 GB por d√≠a
- **CPU al 671%** en TimescaleDB (sobrecarga de queries)

---

## üî¥ PROBLEMAS IDENTIFICADOS

### 1. **TimescaleDB: `scan_results` - 10 GB / 12.5M filas**

```
Tabla: scan_results
Tama√±o: 10,012 MB (10 GB)
Filas: 12,536,682 filas
Per√≠odo: 29-oct-2025 ‚Üí 11-nov-2025 (13 d√≠as)
Tasa: ~965,000 filas/d√≠a
```

**Problema**: Guarda TODOS los resultados del scanner sin pol√≠tica de retenci√≥n.

**Impacto**:

- Queries cada vez m√°s lentas
- Consumo creciente de RAM
- CPU al 671% (6.7 cores trabajando constantemente)

---

### 2. **TimescaleDB: `volume_slots` - 1.6 GB**

```
Tabla: volume_slots
Tama√±o: 1,620 MB
```

**Problema**: Acumula slots de volumen hist√≥ricos sin l√≠mite.

---

### 3. **Redis Streams sin MAXLEN**

```
snapshots:raw:              50,003 mensajes
stream:ranking:deltas:      20,000 mensajes
stream:realtime:aggregates: 10,042 mensajes
```

**Problema**: Los streams crecen infinitamente sin MAXLEN, consumiendo RAM.

---

## ‚úÖ SOLUCIONES INMEDIATAS

### SOLUCI√ìN 1: Pol√≠ticas de Retenci√≥n en TimescaleDB

**A. Para `scan_results` (retener solo 7 d√≠as):**

```sql
-- Agregar pol√≠tica de retenci√≥n: mantener solo √∫ltimos 7 d√≠as
SELECT add_retention_policy('scan_results', INTERVAL '7 days');

-- Limpiar datos viejos AHORA
DELETE FROM scan_results WHERE time < NOW() - INTERVAL '7 days';

-- Hacer VACUUM para recuperar espacio
VACUUM FULL scan_results;
```

**Ahorro esperado**: ~8 GB (mantener solo 7 d√≠as vs 13 d√≠as actuales)

---

**B. Para `volume_slots` (retener solo 30 d√≠as):**

```sql
-- Agregar pol√≠tica de retenci√≥n
SELECT add_retention_policy('volume_slots', INTERVAL '30 days');

-- Limpiar datos viejos
DELETE FROM volume_slots WHERE time < NOW() - INTERVAL '30 days';

-- VACUUM
VACUUM FULL volume_slots;
```

---

### SOLUCI√ìN 2: L√≠mites en Redis Streams

**Modificar los servicios para usar MAXLEN:**

En `data_ingest`, `scanner`, `analytics`:

```python
# ANTES (sin l√≠mite):
await redis_client.xadd("snapshots:raw", {"data": ...})

# DESPU√âS (con l√≠mite de 10,000 mensajes):
await redis_client.xadd(
    "snapshots:raw",
    {"data": ...},
    maxlen=10000,
    approximate=True  # M√°s eficiente
)
```

**Streams a modificar:**

- `snapshots:raw`: MAXLEN 10,000
- `stream:ranking:deltas`: MAXLEN 5,000
- `stream:realtime:aggregates`: MAXLEN 5,000
- `tickers:filtered`: MAXLEN 1,000

---

### SOLUCI√ìN 3: L√≠mites de Memoria en Docker Compose

**Actualizar `docker-compose.yml`:**

```yaml
services:
  timescaledb:
    # ... resto de configuraci√≥n
    deploy:
      resources:
        limits:
          memory: 4G # M√°ximo 4GB
        reservations:
          memory: 2G # M√≠nimo 2GB

  redis:
    # ... resto de configuraci√≥n
    deploy:
      resources:
        limits:
          memory: 2G # Ya est√° configurado
        reservations:
          memory: 512M

  scanner:
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  analytics:
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
```

---

## üîß SCRIPT DE LIMPIEZA INMEDIATA

```bash
#!/bin/bash
# cleanup_memory.sh

echo "üßπ Limpiando TimescaleDB..."

docker exec tradeul_timescale psql -U tradeul_user -d tradeul << EOF

-- 1. Agregar pol√≠ticas de retenci√≥n
SELECT add_retention_policy('scan_results', INTERVAL '7 days', if_not_exists => true);
SELECT add_retention_policy('volume_slots', INTERVAL '30 days', if_not_exists => true);

-- 2. Limpiar datos antiguos
DELETE FROM scan_results WHERE time < NOW() - INTERVAL '7 days';
DELETE FROM volume_slots WHERE time < NOW() - INTERVAL '30 days';

-- 3. Mostrar tama√±os actuales
SELECT
  hypertable_name,
  pg_size_pretty(hypertable_size(format('%I.%I', hypertable_schema, hypertable_name)::regclass)) as size
FROM timescaledb_information.hypertables
ORDER BY hypertable_size(format('%I.%I', hypertable_schema, hypertable_name)::regclass) DESC;

EOF

echo "üßπ Limpiando Redis streams..."

docker exec tradeul_redis redis-cli XTRIM "snapshots:raw" MAXLEN ~ 1000
docker exec tradeul_redis redis-cli XTRIM "stream:ranking:deltas" MAXLEN ~ 1000
docker exec tradeul_redis redis-cli XTRIM "stream:realtime:aggregates" MAXLEN ~ 1000

echo "‚úÖ Limpieza completada"
echo "Revisa el uso de memoria con: docker stats --no-stream"
```

---

## üìä RESULTADOS ESPERADOS

**Antes:**

- TimescaleDB: 10 GB + crecimiento continuo
- Redis: 674 MB
- Total: ~11 GB
- Crecimiento: ~1.5 GB/d√≠a

**Despu√©s de aplicar soluciones:**

- TimescaleDB: ~2-3 GB (estable)
- Redis: ~200 MB (estable)
- Total: ~2.5-3.5 GB (estable)
- Crecimiento: 0 GB/d√≠a (auto-limpieza)

---

## üéØ PLAN DE ACCI√ìN RECOMENDADO

### INMEDIATO (hoy):

1. ‚úÖ Ejecutar script de limpieza `cleanup_memory.sh`
2. ‚úÖ Agregar pol√≠ticas de retenci√≥n en TimescaleDB
3. ‚úÖ Hacer VACUUM FULL para recuperar espacio

### CORTO PLAZO (esta semana):

4. ‚ö†Ô∏è Modificar servicios para usar MAXLEN en streams
5. ‚ö†Ô∏è Agregar l√≠mites de memoria en docker-compose.yml
6. ‚ö†Ô∏è Implementar compresi√≥n en TimescaleDB hypertables

### MEDIANO PLAZO (pr√≥ximas semanas):

7. üìà Monitoreo autom√°tico de memoria
8. üìà Alertas cuando uso > 80%
9. üìà Dashboard de m√©tricas

---

## üîç MONITORING CONTINUO

**Comando para verificar uso de memoria:**

```bash
# Ver consumo actual
docker stats --no-stream

# Ver tama√±o de tablas en TimescaleDB
docker exec tradeul_timescale psql -U tradeul_user -d tradeul -c "
  SELECT
    hypertable_name,
    pg_size_pretty(hypertable_size(format('%I.%I', hypertable_schema, hypertable_name)::regclass)) as size
  FROM timescaledb_information.hypertables;
"

# Ver streams en Redis
docker exec tradeul_redis redis-cli --scan --pattern "stream:*" | \
  xargs -I {} docker exec tradeul_redis redis-cli XLEN {}
```

---

## üìù NOTAS ADICIONALES

### ¬øPor qu√© crece tanto `scan_results`?

El scanner est√° guardando resultados cada pocos segundos durante todo el d√≠a de mercado:

- **Frecuencia**: cada 5 segundos
- **Tickers**: ~1000 tickers filtrados
- **Sesiones**: pre-market, market, after-hours
- **Horas activas**: ~16 horas/d√≠a
- **C√°lculo**: 1000 tickers √ó (16h √ó 3600s / 5s) = ~11.5M filas/d√≠a

### Alternativas para reducir a√∫n m√°s:

1. **Guardar solo top 100 por sesi√≥n** (en lugar de top 1000)
2. **Aumentar intervalo de guardado** (de 5s a 30s)
3. **Guardar snapshots agregados** (1 por minuto con promedios)
4. **Usar una tabla separada para hist√≥ricos** (mover a cold storage)

---

## ‚ö†Ô∏è ADVERTENCIA

**NO ejecutar VACUUM FULL durante horario de mercado**, puede tardar varios minutos y bloquear la tabla.

**Mejor momento**: fines de semana o despu√©s de las 8 PM ET (1 AM Madrid).
