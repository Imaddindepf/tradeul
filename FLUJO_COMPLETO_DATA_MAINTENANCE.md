# üìä AN√ÅLISIS COMPLETO: Servicio data_maintenance - TODO lo que hace

**Fecha:** 2025-11-26  
**Estado:** Sistema completo en producci√≥n

---

## üì¶ ARCHIVOS MODIFICADOS HOY (2025-11-25/26)

### ‚úÖ Creados/Modificados para limpieza de cache:
```
1. /opt/tradeul/services/data_maintenance/cache_clear_scheduler.py (NUEVO)
2. /opt/tradeul/services/data_maintenance/tasks/clear_realtime_caches.py (NUEVO)
3. /opt/tradeul/services/data_maintenance/main.py (MODIFICADO)
4. /opt/tradeul/services/websocket_server/src/cache_cleaner.js (NUEVO)
5. /opt/tradeul/services/websocket_server/src/index.js (MODIFICADO)
```

### ‚úÖ Archivos existentes (NO modificados, pero importantes):
```
6. /opt/tradeul/services/data_maintenance/maintenance_scheduler.py
7. /opt/tradeul/services/data_maintenance/task_orchestrator.py
8. /opt/tradeul/services/data_maintenance/tasks/load_ohlc.py
9. /opt/tradeul/services/data_maintenance/tasks/load_volume_slots.py
10. /opt/tradeul/services/data_maintenance/tasks/calculate_atr.py
11. /opt/tradeul/services/data_maintenance/tasks/calculate_rvol_averages.py
12. /opt/tradeul/services/data_maintenance/tasks/enrich_metadata.py
13. /opt/tradeul/services/data_maintenance/tasks/auto_recover_missing_tickers.py
14. /opt/tradeul/services/data_maintenance/tasks/sync_redis.py
15. /opt/tradeul/services/data_maintenance/tasks/cleanup_old_data.py
```

---

## ‚è∞ L√çNEA DE TIEMPO COMPLETA (24 HORAS)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FLUJO DIARIO COMPLETO del data_maintenance                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

03:00 AM EST ‚Üí üî• LIMPIEZA DE CACHES (NUEVO - lo que acabamos de implementar)
    ‚îú‚îÄ Duraci√≥n: 5 segundos
    ‚îú‚îÄ Operaci√≥n: Pub/Sub + limpia memoria WebSocket
    ‚îî‚îÄ Tablas tocadas: NINGUNA
    
04:00 AM EST ‚Üí Pre-market inicia (scanner actualiza datos)
    ‚îî‚îÄ Scanner actualiza: scanner:category:* en Redis
    
09:30 AM EST ‚Üí Market open (trading normal)
    
16:00 PM EST ‚Üí Market close
    
17:00 PM EST ‚Üí üöÄ MANTENIMIENTO PRINCIPAL (existente desde antes)
    ‚îú‚îÄ Duraci√≥n: 5-15 minutos
    ‚îú‚îÄ 7 tareas secuenciales
    ‚îî‚îÄ Sincroniza BD con datos del d√≠a

20:00 PM EST ‚Üí Post-market cierra ‚Üí CLOSED
    
Domingo 03:00 AM ‚Üí üßπ CLEANUP SEMANAL (existente)
    ‚îî‚îÄ Borra datos > 15 d√≠as de volume_slots
```

---

## üöÄ MANTENIMIENTO PRINCIPAL (5:00 PM - Despu√©s del cierre)

### **Ejecuta 7 TAREAS SECUENCIALES:**

---

### **TAREA 1: LoadOHLCTask** (Cargar datos OHLC del d√≠a)

**Qu√© hace:**
```
Lee datos de cierre del d√≠a desde Polygon API
Guarda en PostgreSQL para c√°lculos hist√≥ricos
```

**Tablas PostgreSQL AFECTADAS:**
```sql
INSERT INTO market_data_daily (
    symbol, date, open, high, low, close, volume, vwap
)
```

**Tabla:** `market_data_daily`
- **Acci√≥n:** INSERT (1 row por ticker)
- **Cantidad:** ~12,000 rows (1 por cada ticker activo)

**Redis:**
- ‚ùå No toca Redis directamente

**Duraci√≥n:** ~2-3 minutos

---

### **TAREA 2: LoadVolumeSlotsTask** (Cargar volumen por slots del d√≠a)

**Qu√© hace:**
```
Calcula volumen acumulado cada 5 minutos del d√≠a
Guarda en TimescaleDB para c√°lculo de RVOL
```

**Tablas PostgreSQL AFECTADAS:**
```sql
INSERT INTO volume_slots (
    symbol, date, slot_number, slot_time, volume_accumulated
)
```

**Tabla:** `volume_slots`
- **Acci√≥n:** INSERT (m√∫ltiples rows por ticker)
- **Cantidad:** ~12,000 tickers √ó 78 slots = ~936,000 rows
- **Slots:** 78 (9:30 AM - 4:00 PM en bloques de 5 min)

**Redis:**
```
LEE: snapshot:enriched:latest (para obtener s√≠mbolos activos)
```

**Duraci√≥n:** ~3-5 minutos

---

### **TAREA 3: CalculateATRTask** (Calcular ATR para todos los tickers)

**Qu√© hace:**
```
Calcula Average True Range (ATR) basado en √∫ltimos 14 d√≠as
Guarda en Redis para uso inmediato por scanner/analytics
```

**Tablas PostgreSQL LE√çDAS:**
```sql
SELECT * FROM market_data_daily 
WHERE symbol = ? AND date >= ?
ORDER BY date DESC LIMIT 14
```

**Redis ACTUALIZADO:**
```
HSET atr:data:<symbol> 
‚îú‚îÄ "atr" ‚Üí 1.25
‚îú‚îÄ "atr_percent" ‚Üí 2.5
‚îú‚îÄ "date" ‚Üí "2025-11-25"
‚îî‚îÄ TTL: 24 horas
```

**Keys Redis AFECTADAS:**
```
atr:data:<symbol>  (1 key por ticker)
Total: ~12,000 keys
```

**Duraci√≥n:** ~1-2 minutos

---

### **TAREA 4: CalculateRVOLHistoricalAveragesTask** (Promedios hist√≥ricos RVOL)

**Qu√© hace:**
```
Calcula volumen promedio hist√≥rico por slot (5 d√≠as lookback)
Guarda en Redis para c√°lculo r√°pido de RVOL
```

**Tablas PostgreSQL LE√çDAS:**
```sql
SELECT slot_number, AVG(volume_accumulated) as avg_vol
FROM volume_slots
WHERE symbol = ? AND date >= ?
GROUP BY slot_number
```

**Redis ACTUALIZADO:**
```bash
# Primero: BORRA todas las keys antiguas
DEL rvol:hist:avg:*  (borra ~11,500 keys)

# Luego: Crea keys nuevas
HMSET rvol:hist:avg:<symbol>
‚îú‚îÄ "0" ‚Üí "12500"    (slot 0: 9:30-9:35 AM promedio)
‚îú‚îÄ "1" ‚Üí "15000"    (slot 1: 9:35-9:40 AM promedio)
‚îú‚îÄ "2" ‚Üí "13200"
... (78 slots por ticker)
‚îî‚îÄ TTL: 14 horas
```

**Keys Redis AFECTADAS:**
```
BORRA: rvol:hist:avg:*  (~11,500 keys)
CREA: rvol:hist:avg:<symbol>  (~11,500 keys nuevas)
```

**Duraci√≥n:** ~2-3 minutos

---

### **TAREA 5: EnrichMetadataTask** (Enriquecer metadata de tickers)

**Qu√© hace:**
```
Actualiza informaci√≥n fundamental de tickers (market cap, sector, etc.)
Lee desde Polygon API y guarda en Redis
```

**Tablas PostgreSQL:**
- ‚ùå No toca tablas

**Redis ACTUALIZADO:**
```
SET metadata:ticker:<symbol>
{
  "symbol": "AAPL",
  "name": "Apple Inc",
  "market_cap": 3000000000000,
  "sector": "Technology",
  "industry": "Consumer Electronics",
  "float_shares": 15000000000,
  "shares_outstanding": 15500000000,
  ...
}
TTL: 24 horas
```

**Keys Redis AFECTADAS:**
```
metadata:ticker:<symbol>  (~12,000 keys)
Acci√≥n: UPDATE (sobrescribe con datos frescos)
```

**Duraci√≥n:** ~1-2 minutos

---

### **TAREA 6: AutoRecoverMissingTickersTask** (Auto-detectar tickers nuevos)

**Qu√© hace:**
```
Compara tickers en snapshot vs universe
Agrega tickers nuevos que aparecieron hoy
```

**Tablas PostgreSQL:**
- ‚ùå No modifica tablas directamente

**Redis LE√çDO:**
```
GET snapshot:enriched:latest  (tickers activos hoy)
SMEMBERS ticker:universe  (universe completo)
```

**Redis ACTUALIZADO:**
```
SADD ticker:universe <nuevo_ticker>
SET metadata:ticker:<nuevo_ticker> {...}
```

**Keys Redis AFECTADAS:**
```
ticker:universe  (1 SET, agrega nuevos tickers)
metadata:ticker:<nuevo_ticker>  (1 key por ticker nuevo, usualmente 0-5)
```

**Duraci√≥n:** ~30 segundos

---

### **TAREA 7: SyncRedisTask** (Sincronizar Redis con BD)

**Qu√© hace:**
```
Sincroniza caches de Redis con datos en PostgreSQL
Asegura consistencia entre BD y cache
```

**Tablas PostgreSQL LE√çDAS:**
```sql
-- ATR data
SELECT symbol, atr, atr_percent FROM latest_atr

-- Metadata
SELECT * FROM ticker_metadata WHERE symbol IN (...)

-- Volume averages
SELECT symbol, slot_number, avg_vol FROM volume_slot_averages
```

**Redis ACTUALIZADO:**
```bash
# 1. Universe
DEL ticker:universe
SADD ticker:universe <symbol1> <symbol2> ... (12,383 s√≠mbolos)

# 2. ATR data (refresh)
HSET atr:data:<symbol> ...
TTL: 24h

# 3. Metadata (refresh si desincronizada)
SET metadata:ticker:<symbol> ...
TTL: 24h

# 4. Volume averages (refresh si desincronizada)
HMSET rvol:hist:avg:<symbol> ...
TTL: 14h

# 5. Limpieza de keys obsoletas
# Busca keys de tickers que ya no existen
DEL metadata:ticker:<ticker_inactivo>
```

**Keys Redis AFECTADAS:**
```
ticker:universe  (1 SET, reconstruido)
atr:data:*  (~12,000 keys, refresh)
metadata:ticker:*  (~12,000 keys, verificados)
rvol:hist:avg:*  (~11,500 keys, verificados)
Keys obsoletas: BORRADAS (si existen)
```

**Duraci√≥n:** ~1-2 minutos

---

### **TAREA 8 (Domingos): CleanupOldDataTask** (Limpieza semanal)

**Qu√© hace:**
```
Solo los DOMINGOS
Borra datos > 15 d√≠as de volume_slots
Mantiene BD optimizada
```

**Tablas PostgreSQL AFECTADAS:**
```sql
DELETE FROM volume_slots 
WHERE date < '2025-11-11'  -- (15 d√≠as atr√°s)
```

**Tabla:** `volume_slots`
- **Acci√≥n:** DELETE
- **Cantidad:** ~600,000 rows √ó d√≠as antiguos

**Redis:**
- ‚ùå No toca Redis

**Duraci√≥n:** ~30 segundos

---

## üìä RESUMEN DE OPERACIONES EN REDIS

### **A las 3:00 AM (Cache Clear - NUEVO):**
```
OPERACI√ìN: PUBLISH trading:new_day
KEYS AFECTADAS: 0 (solo Pub/Sub)
DURACI√ìN: < 1 segundo
```

### **A las 5:00 PM (Mantenimiento Principal - EXISTENTE):**
```
OPERACIONES TOTALES: ~40,000+
‚îú‚îÄ INSERTS PostgreSQL: ~950,000 rows
‚îú‚îÄ DELETE Redis keys: ~11,500 (rvol promedios viejos)
‚îú‚îÄ CREATE Redis keys: ~35,000 (atr, rvol, metadata)
‚îú‚îÄ UPDATE Redis keys: ~12,000 (metadata refresh)
‚îî‚îÄ CLEANUP obsoletas: ~10-50 keys

DURACI√ìN TOTAL: 10-15 minutos
```

---

## üéØ DOS SISTEMAS DIFERENTES

### **Sistema 1: Cache Clear (3:00 AM) - LO QUE IMPLEMENTAMOS HOY**

```
CU√ÅNDO: 3:00 AM (1h antes pre-market)
QU√â: Limpia cache EN MEMORIA del WebSocket
REDIS: Solo 1 PUBLISH (Pub/Sub)
TABLAS BD: NO toca nada
DURACI√ìN: 5 segundos
PROP√ìSITO: Evitar datos de ayer en pre-market
```

### **Sistema 2: Mantenimiento Diario (5:00 PM) - YA EXIST√çA DESDE ANTES**

```
CU√ÅNDO: 5:00 PM (despu√©s del cierre)
QU√â: Sincroniza BD con datos del d√≠a
REDIS: ~40,000 operaciones (refresh completo)
TABLAS BD: INSERT ~950,000 rows
DURACI√ìN: 10-15 minutos
PROP√ìSITO: Mantener datos hist√≥ricos actualizados
```

---

## üìã KEYS DE REDIS (Estado actual)

### **Keys que usa el sistema:**

```bash
# Categor√≠as del Scanner (actualizadas cada 2-5 seg por scanner)
scanner:category:winners           ‚Üí Lista JSON [100 tickers]
scanner:category:losers            ‚Üí Lista JSON [100 tickers]
scanner:category:gappers_up        ‚Üí Lista JSON [100 tickers]
scanner:category:gappers_down      ‚Üí Lista JSON [100 tickers]
scanner:category:momentum_up       ‚Üí Lista JSON [100 tickers]
scanner:category:momentum_down     ‚Üí Lista JSON [100 tickers]
scanner:category:new_highs         ‚Üí Lista JSON [100 tickers]
scanner:category:new_lows          ‚Üí Lista JSON [100 tickers]
scanner:category:high_volume       ‚Üí Lista JSON [100 tickers]
scanner:category:anomalies         ‚Üí Lista JSON [100 tickers]
scanner:category:reversals         ‚Üí Lista JSON [0-100 tickers]

# Sequences (control de versi√≥n)
scanner:sequence:winners           ‚Üí Integer (ej: 4179)
scanner:sequence:losers            ‚Üí Integer
... (11 sequences)

# Snapshots de Polygon
snapshot:polygon:latest            ‚Üí JSON {count: 11283, tickers: [...]}
snapshot:enriched:latest           ‚Üí JSON {count: 11283, tickers: [...], rvol, atr}

# Metadata (actualizada por maintenance 5 PM)
metadata:ticker:AAPL               ‚Üí JSON {name, market_cap, sector, ...}
metadata:ticker:TSLA               ‚Üí JSON {name, market_cap, sector, ...}
... (~12,370 keys)

# ATR Cache (actualizado por maintenance 5 PM)
atr:data:AAPL                      ‚Üí HASH {atr, atr_percent, date}
atr:data:TSLA                      ‚Üí HASH {atr, atr_percent, date}
... (~12,000 keys)

# RVOL Historical Averages (actualizado por maintenance 5 PM)
rvol:hist:avg:AAPL                 ‚Üí HASH {0: 12500, 1: 15000, ...}
rvol:hist:avg:TSLA                 ‚Üí HASH {0: 250000, 1: 280000, ...}
... (~11,500 keys)

# Universe
ticker:universe                    ‚Üí SET {AAPL, TSLA, MSFT, ...}
                                     (12,383 s√≠mbolos)

# Polygon WS
polygon_ws:active_tickers          ‚Üí SET {AAPL, TSLA, ...}
                                     (s√≠mbolos suscritos activamente)

# Control de mantenimiento
maintenance:executed:2025-11-25    ‚Üí "1" (flag de ejecuci√≥n)
maintenance:status:2025-11-25      ‚Üí JSON {tasks: {...}, all_success: true}
maintenance:last_run               ‚Üí "2025-11-25"
```

---

## üîÑ FLUJO DETALLADO: QU√â PASA A LAS 3:00 AM (en 9 minutos)

### **03:00:00.000 - Detecci√≥n**
```python
# cache_clear_scheduler.py
current_time.hour == 3 and current_time.minute == 0
‚úÖ Condici√≥n cumplida
```

### **03:00:00.100 - Log inicial**
```json
{
  "event": "cache_clear_time_detected",
  "time": "03:00 AM EST",
  "date": "2025-11-26"
}
```

### **03:00:00.200 - Execute task**
```python
result = await clear_task.execute(current_date)
```

### **03:00:00.300 - Publish Pub/Sub**
```python
await redis.client.publish(
    "trading:new_day",
    '{"event":"new_trading_day","date":"2025-11-26","action":"clear_caches"}'
)
```

**Redis:**
```
COMANDO: PUBLISH trading:new_day '{"event":...}'
SUBSCRIBERS: 1 (websocket_server)
LATENCIA: < 1ms
```

### **03:00:00.301 - WebSocket recibe**
```javascript
// WebSocket Server escucha canal "trading:new_day"
redisSubscriber.on("message", (channel, message) => {
    event = JSON.parse(message);
    if (event.action === "clear_caches") {
        lastSnapshots.clear();  // ‚Üê LIMPIA MEMORIA
    }
});
```

**WebSocket Memoria:**
```
ANTES: lastSnapshots.size = 11 (11 categor√≠as con 100 tickers c/u)
OPERACI√ìN: lastSnapshots.clear()
DESPU√âS: lastSnapshots.size = 0
```

### **03:00:00.500 - Intento HTTP (falla, normal)**
```python
# Intenta: POST http://websocket_server:9000/api/clear-cache
# Resultado: Connection refused (endpoint no existe, no importa)
# Pub/Sub ya funcion√≥ ‚úÖ
```

### **03:00:00.600 - Log final**
```json
{
  "event": "clear_caches_task_completed",
  "services_notified": 1,
  "caches_cleared": 1
}

{
  "event": "cache_clear_executed_successfully",
  "date": "2025-11-26"
}
```

### **03:00:00.700 - Actualiza flag**
```python
self.last_clear_date = date(2025, 11, 26)
# Previene ejecuci√≥n m√∫ltiple el mismo d√≠a
```

### **03:00:30 - Siguiente check**
```python
# Verifica de nuevo
is_clear_time = (hour == 3 and minute == 0)  # False (minute=30)
# No ejecuta nada, espera otros 30 seg
```

---

## üîç VERIFICACI√ìN PASO A PASO (3:05 AM)

```bash
# 1. Ver que se ejecut√≥ a las 3:00
docker logs tradeul_data_maintenance --since 10m --timestamps | grep "03:00"

# Esperado:
# 2025-11-26T08:00:00.xxxZ cache_clear_time_detected
# 2025-11-26T08:00:00.xxxZ new_day_event_published
# 2025-11-26T08:00:00.xxxZ cache_clear_executed_successfully

# 2. Ver que WebSocket limpi√≥
docker logs tradeul_websocket_server --since 10m --timestamps | grep "03:00"

# Esperado:
# 2025-11-26T08:00:00.xxxZ "Cache cleared for new trading day"

# 3. Verificar Redis keys (deben estar TODAS)
export $(grep REDIS_PASSWORD /opt/tradeul/.env | xargs)
docker exec tradeul_redis redis-cli -a "$REDIS_PASSWORD" --no-auth-warning DBSIZE

# Esperado: ~48,967 keys (igual que antes)

# 4. Verificar que scanner:category a√∫n tiene datos (hasta las 4 AM)
docker exec tradeul_redis redis-cli -a "$REDIS_PASSWORD" --no-auth-warning \
  GET "scanner:category:winners" | jq 'length'

# Esperado a las 3:05 AM: 100 (datos de ayer, normal)
# Esperado a las 4:05 AM: 2-5 (datos de hoy, despu√©s de scanner update)
```

---

## üìä IMPACTO EN EL SISTEMA

### **A las 3:00 AM (Cache Clear):**
```
CPU: < 1% por 1 segundo
Memoria: -10MB (libera cache)
Red: 1 operaci√≥n Pub/Sub (< 1KB)
Disco: 0 operaciones
BD: 0 operaciones
```

### **A las 5:00 PM (Mantenimiento Principal):**
```
CPU: 20-40% por 10-15 minutos
Memoria: +100MB temporal
Red: ~50,000 requests a Polygon API
Disco: Escribe ~950,000 rows en BD
BD: INSERT masivo + CLEANUP
```

---

## üéØ CONCLUSI√ìN

### Qu√© implementamos HOY:
```
‚úÖ Sistema de limpieza de cache a las 3:00 AM
‚úÖ Solo afecta MEMORIA del WebSocket (lastSnapshots)
‚úÖ NO toca Redis keys
‚úÖ NO toca tablas PostgreSQL
‚úÖ Duraci√≥n: 5 segundos
```

### Qu√© ya exist√≠a (NO lo tocamos):
```
‚úÖ Mantenimiento diario a las 5:00 PM
‚úÖ 7 tareas que sincronizan BD
‚úÖ Actualiza ~40,000 keys de Redis
‚úÖ Inserta ~950,000 rows en PostgreSQL
‚úÖ Duraci√≥n: 10-15 minutos
```

---

**Ambos sistemas son independientes y complementarios.**

---

‚è∞ **EJECUCI√ìN EN:** 9 minutos (3:00 AM)

